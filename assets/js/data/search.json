[ { "title": "Redis 持久化", "url": "/posts/redis-persistence/", "categories": "Redis, RDB&AFO", "tags": "Redis", "date": "2022-04-17 22:00:00 +0800", "snippet": "Redis 持久化Redis 的持久化机制有两种 第一种是快照 RDB，是一次全量备份 第二种是 AOF 日志，是连续的增量备份快照是内存数据的二进制序列化形式，在存储上非常紧凑，而 AOF 日志记录 的是内存数据修改的指令记录文本。AOF 日志在长期的运行过程中会变的无比庞大，数据库重启时需要加载 AOF 日志进行指令重放，这个时间就会无比漫长。所以需要定期进行 AOF 重写，给 AOF 日志进行瘦身。RDB 快照持久化Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行： 执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，会阻塞主线程； 执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以避免主线程的阻塞；Redis 还可以通过配置文件的选项来实现每隔一段时间自动执行一次 bgsave 命令，默认会提供以下配置：save 900 1save 300 10save 60 10000别看选项名叫 save，实际上执行的是 bgsave 命令，也就是会创建子进程来生成 RDB 快照文件。只要满足上面条件的任意一个，就会执行 bgsave，它们的意思分别是： 900 秒之内，对数据库进行了至少 1 次修改； 300 秒之内，对数据库进行了至少 10 次修改； 60 秒之内，对数据库进行了至少 10000 次修改。我们知道 Redis 是单线程程序，这个线程要同时负责多个客户端套接字的并发读写操作和内存数据结构的逻辑读写。在服务线上请求的同时，Redis 还需要进行内存快照，内存快照要求 Redis 必须进行文件 IO 操作，可文件 IO 操作是不能使用多路复用 API。这意味着单线程同时在服务线上的请求还要进行文件 IO 操作，文件 IO 操作会严重拖垮服务器请求的性能。还有个重要的问题是为了不阻塞线上的业务，就需要边持久化边响应客户端请求。持久化的同时，内存数据结构还在改变，比如一个大型的 hash 字典正在持久化，结果一个请求过来把它给删掉了，还没持久化完呢，这尼玛要怎么搞？Redis 使用操作系统的多进程 COW(Copy On Write) 机制来实现快照持久化。fork 多进程Redis 在持久化时会调用 glibc 的函数 fork 产生一个子进程，快照持久化完全交给子进程来处理，父进程继续处理客户端请求。子进程刚刚产生时，它和父进程共享内存里面的代码段和数据段。这是 Linux 操作系统的机制，为了节约内存资源，所以尽可能让它们共享起来。在进程分离的一瞬间，内存的增长几乎没有明显变化。执行 bgsave 命令的时候，会通过 fork() 创建子进程，此时子进程和父进程是共享同一片内存数据的，因为创建子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个，此时如果主线程执行读操作，则主线程和 bgsave 子进程互相不影响。子进程做数据持久化，它不会修改现有的内存数据结构，它只是对数据结构进行遍历读取，然后序列化写到磁盘中。但是父进程不一样，它必须持续服务客户端请求，然后对内存数据结构进行不间断的修改。随着父进程修改操作的持续进行，越来越多的共享页面被分离出来，内存就会持续增长。但是也不会超过原有数据内存的 2 倍大小。另外一个 Redis 实例里冷数据占的比例往往是比较高的，所以很少会出现所有的页面都会被分离，被分离的往往只有其中一部分页面。每个页面的大小只有 4K，一个 Redis 实例里面一般都会有成千上万的页面。。子进程因为数据没有变化，它能看到的内存里的数据在进程产生的一瞬间就凝固了，再也不会改变，这也是为什么 Redis 的持久化叫「快照」的原因。接下来子进程就可以非常安心的遍历数据了进行序列化写磁盘了。如果主线程（父进程）要修改共享数据里的某一块数据（比如键值对 A）时，就会发生写时复制，于是这块数据的物理内存就会被复制一份（键值对 A&#39;），然后主线程在这个数据副本（键值对 A&#39;）进行修改操作。与此同时，bgsave 子进程可以继续把原来的数据（键值对 A）写入到 RDB 文件。所以 Redis 在使用 bgsave 快照过程中，如果主线程修改了内存数据，不管是否是共享的内存数据，RDB 快照都无法写入主线程刚修改的数据，因为此时主线程（父进程）的内存数据和子进程的内存数据已经分离了，子进程写入到 RDB 文件的内存数据只能是原本的内存数据。AOF 持久化AOF (Append Only File) 日志存储的是 Redis 服务器的顺序指令序列，AOF 日志只记录对内存进行修改的指令记录。在 Redis 中 AOF 持久化功能默认是不开启的，需要我们修改 redis.conf 配置文件中的以下参数：appendonly noappendfilename &quot;appendonly.aof&quot;AOF 日志文件其实就是普通的文本，我们可以通过 cat 命令查看里面的内容Redis 会在收到客户端修改指令后，先执行指令才将日志存盘，进行参数校验进行逻辑处理后，如果没问题，就立即将该指令文本存储到 AOF 日志中。这点不同于 leveldb、hbase 等存储引擎，它们都是先存储日志再做逻辑处理。先执行指令再将日志存盘的好处： 避免 AOF 写入的额外检查开销，因为如果先将写操作命令记录到 AOF 日志里，再执行该命令的话，如果当前的命令语法有问题，那么如果不进行命令语法检查，该错误的命令记录到 AOF 日志里后，Redis 在使用日志恢复数据时，就可能会出错。而如果先执行写操作命令再记录日志的话，只有在该命令执行成功后，才将命令记录到 AOF 日志里，这样就不用额外的检查开销，保证记录在 AOF 日志里的命令都是可执行并且正确的。 不会阻塞当前写操作命令的执行，因为当写操作命令执行成功后，才会将命令记录到 AOF 日志。先执行指令再将日志存盘的风险： 执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，数据就会有丢失的风险。 由于写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前写操作命令的执行，但是可能会给「下一个」命令带来阻塞风险。Redis 写入 AOF 步骤 Redis 执行完写操作命令后，会将命令追加到 server.aof_buf 缓冲区； 然后通过 write() 系统调用，将 aof_buf 缓冲区的数据写入到 AOF 文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 page cache，等待内核将数据写入硬盘； 具体内核缓冲区的数据什么时候写入到硬盘，由内核决定。appendfsync 写回策略Redis 提供的 AOF 配置项 appendfsync 写回策略直接决定 AOF 持久化功能的效率和安全性。 always：同步写回，写指令执行完毕立马将 aof_buf 缓冲区中的内容刷写到 AOF 文件。 everysec：每秒写回，写指令执行完，日志只会写到 AOF 文件缓冲区，每隔一秒就把缓冲区内容同步到磁盘。 no：操作系统控制，写执行执行完毕，把日志写到 AOF 文件内存缓冲区，由操作系统决定何时刷写到磁盘。这 3 种写回策略都无法能完美解决 「主进程阻塞」和「减少数据丢失」的问题，原因如下： Always 策略 可以最大程度保证数据不丢失，但是由于它每执行一条写操作命令就同步将 AOF 内容写回硬盘，所以是不可避免会影响主进程的性能； No 策略 是交由操作系统来决定何时将 AOF 日志内容写回硬盘，相比于 Always 策略性能较好，但是操作系统写回硬盘的时机是不可预知的，如果 AOF 日志内容没有写回硬盘，一旦服务器宕机，就会丢失不定数量的数据。 Everysec 策略 是折中的一种方式，避免了 Always 策略的性能开销，也比 No 策略更能避免数据丢失，当然如果上一秒的写操作命令日志没有写回到硬盘，发生了宕机，这一秒内的数据自然也会丢失。fsync()AOF 日志是以文件的形式存在的，当程序对 AOF 日志文件进行写操作时，实际上是将内容写到了内核为文件描述符分配的一个内存缓存中，然后内核会异步将脏数据刷回到磁盘的。Linux 的 glibc提供了 fsync(int fd) 函数可以将指定文件的内容强制从内核缓存刷到磁盘。只要 Redis 进程实时调用 fsync 函数就可以保证 aof 日志不丢失。但是 fsync 是一个磁盘 IO 操作，它很慢！如果 Redis 执行一条指令就要 fsync 一次，那么 Redis 高性能的地位就不保了。所以在生产环境的服务器中，Redis 通常是每隔 1s 左右执行一次 fsync 操作，周期 1s 是可以配置的。这是在数据安全性和性能之间做了一个折中，在保持高性能的同时，尽可能使得数据少丢失。Redis 同样也提供了另外两种策略，一个是 NO fsync——让操作系统来决定何时同步磁盘，很不安全，另一个是来一个指令就 always fsync 一次——非常慢。 Always 策略就是每次写入 AOF 文件数据后，就执行 fsync() 函数； Everysec 策略就会创建一个异步任务来执行 fsync() 函数； No 策略就是永不执行 fsync() 函数; 通常 Redis 的主节点是不会进行持久化操作，持久化操作主要在从节点进行。从节点是备份节点，没有来自客户端请求的压力，它的操作系统资源往往比较充沛。AOF 重写Redis 在长期运行的过程中，AOF 的日志会越变越长。如果实例宕机重启，重放整个 AOF 日志会非常耗时，导致长时间 Redis 无法对外提供服务。所以需要对 AOF 日志瘦身。Redis 提供了 bgrewriteaof 指令用于对 AOF 日志进行瘦身。其原理就是开辟一个子进程对内存进行遍历转换成一系列 Redis 的操作指令，序列化到一个新的 AOF 日志文件中。序列化完毕后再将操作期间发生的增量 AOF 日志追加到这个新的 AOF 日志文件中，追加完毕后就立即替代旧的 AOF 日志文件了，瘦身工作就完成了。 主进程可以继续处理命令请求，从而避免阻塞主进程 子进程带有主进程的数据副本，这里使用子进程而不是线程，因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据的安全，而这样就会降低性能。而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读的方式，而当父子进程任意一方修改了该共享内存，就会发生「写时复制」，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。主进程在通过 fork 系统调用生成 bgrewriteaof 子进程时，操作系统会把主进程的「页表」复制一份给子进程，这个页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。这样一来，子进程就共享了父进程的物理内存数据了，这样能够节约物理内存资源，页表对应的页表项的属性会标记该物理内存的权限为只读。不过，当父进程或者子进程在向这个内存发起写操作时，CPU 就会触发写保护中断，这个写保护中断是由于违反权限导致的，然后操作系统会在「写保护中断处理函数」里进行物理内存的复制，并重新设置其内存映射关系，将父子进程的内存读写权限设置为可读写，最后才会对内存进行写操作，这个过程被称为「写时复制(Copy On Write)」。有两个阶段会导致阻塞父进程： 创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关，页表越大，阻塞的时间也越长； 创建完子进程后，如果子进程或者父进程修改了共享数据，就会发生写时复制，这期间会拷贝物理内存，如果内存越大，自然阻塞的时间也越长；在 bgrewriteaof 子进程执行 AOF 重写期间，主进程需要执行以下三个工作: 执行客户端发来的命令； 将执行后的写命令追加到 「AOF 缓冲区」； 将执行后的写命令追加到 「AOF 重写缓冲区」；Redis 4.0 混合持久化重启 Redis 时，我们很少使用 rdb 来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 rdb 来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。将 rdb 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是自持久化开始到持久化结束的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小。于是在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。混合持久化工作在 AOF 日志重写过程。当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样加载的时候速度会很快。加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得数据更少的丢失。" }, { "title": "Map", "url": "/posts/go-map/", "categories": "Go, Map", "tags": "Go", "date": "2022-04-01 22:00:00 +0800", "snippet": "map 结构 hmapmap 类型的变量本质上是一个 hmap 类型的指针：type hmap struct { count int // 已经存储的键值对个数 flags uint8 B uint8 // 常规桶个数等于2^B; map底层的哈希表通过与运算的方式选择桶 noverflow uint16 // 使用的溢出桶数量 hash0 uint32 // hash seed buckets unsafe.Pointer // 常规桶起始地址 oldbuckets unsafe.Pointer // 扩容时保存原来常规桶的地址 nevacuate uintptr // 渐进式扩容时记录下一个要被迁移的旧桶编号 extra *mapextra}// 溢出桶相关信息type mapextra struct { overflow *[]*bmap // 把已经用到的溢出桶链起来 oldoverflow *[]*bmap // 渐进式扩容时，保存旧桶用到的溢出桶 nextOverflow *bmap // 下一个尚未使用的溢出桶} count 表示当前哈希表中的元素数量； B 表示当前哈希表持有的 buckets 数量，但是因为哈希表中桶的数量都 2 的倍数，所以该字段会存储对数，也就是 len(buckets) == 2^B； hash0 是哈希的种子，它能为哈希函数的结果引入随机性，这个值在创建哈希表时确定，并在调用哈希函数时作为参数传入； oldbuckets 是哈希在扩容时用于保存之前 buckets 的字段，它的大小是当前 buckets 的一半； nevacuate 哈希扩容时迁移的进度，也就是下一个要迁移的位置 extra 溢出桶的相关信息map使用的桶很有设计感，每个桶里可以存储8个键值对，并且为了内存使用更加紧凑，8个键放一起，8个值放一起。对应每个key只保存其哈希值的高8位（tophash）。每个键值对的 tophash、key 和 value 的索引顺序一一对应。这就是 map 使用的桶的内存布局。type bmap struct { tophash [bucketCnt]uint8}在运行期间，runtime.bmap 结构体其实不止包含 tophash 字段，因为哈希表中可能存储不同类型的键值对，而且 Go 语言也不支持泛型，所以键值对占据的内存空间大小只能在编译时进行推导。runtime.bmap 中的其他字段在运行时也都是通过计算内存地址的方式访问的，所以它的定义中就不包含这些字段，不过我们能根据编译期间的 cmd/compile/internal/gc.bmap 函数重建它的结构：type bmap struct { topbits [8]uint8 keys [8]keytype values [8]valuetype pad uintptr overflow uintptr}溢出桶 当桶的数量小于 2^4 时，由于数据较少、使用溢出桶的可能性较低，会省略创建的过程以减少额外开销； 当桶的数量多于 2^4 时，会额外创建 2^𝐵−4 个溢出桶；溢出桶的内存布局与之前介绍的常规桶相同。如果哈希表要分配的桶的数目大于 2^4，就会预分配 2^(B-4) 个溢出桶备用。这些常规桶和溢出桶在内存中是连续的，只是前 2^B 个用作常规桶，后面的用作溢出桶。如果当前桶存满了以后，检查 hmap.extra.nextoverflow 还有可用的溢出桶，就在这个桶后面链上这个溢出桶，然后继续往这个溢出桶里存。而 hmap.extra.nextoverflow 继续指向下一个空闲的溢出桶。所以这里解决哈希冲突的方式应该属于拉链法。Go语言中可以通过 == 来比较是否相等的类型，都可以作为 map 的 key 类型。字面量初始化hash := map[string]int{ &quot;1&quot;: 2, &quot;3&quot;: 4, &quot;5&quot;: 6,} 当哈希表中的元素数量少于或者等于 25 个时，编译器会将字面量初始化的结构体将所有的键值对一次加入到哈希表中。 一旦哈希表中元素的数量超过了 25 个，编译器会创建两个数组分别存储键和值，这些键值对会通过如下所示的 for 循环加入哈希hash := make(map[string]int, 26)vstatk := []string{&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, ... ， &quot;26&quot;}vstatv := []int{1, 2, 3, ... , 26}for i := 0; i &amp;lt; len(vstak); i++ { hash[vstatk[i]] = vstatv[i]}hash 桶选择假设哈希值为 hash，桶数量为 m。通常我们有两种方法来选择一个桶: 取模法 hash%m 与运算 hash&amp;amp;(m-1)第二种更加高效，但限制了 m 必须要是2的整数次幂，这样才能保证与运算结果落在 [0,m-1]，而不会出现有些桶注定不会被选中的情况。所以 hmap 中并不直接记录桶的个数，而是记录这个数目是2的多少次幂。hash 扩容 如果超过负载因子(默认6.5)就触发翻倍扩容； hmap.count / 2^hmap.B &amp;gt; 6.5 分配新桶数目是旧桶的 2 倍，hmap.oldbuckets 指向旧桶，hmap.buckets 指向新桶。hmap.nevacuate 为0，表示接下来要迁移编号为0的旧桶。 然后通过渐进式扩容的方式，每次读写map时检测到当前map处在扩容阶段（hmap.oldbuckets != nil），就执行一次迁移工作，把编号为 hmap.nevacuate 的旧桶迁移到新桶，每个旧桶的键值对都会分流到两个新桶中。 编号为 hmap.nevacuate 的旧桶迁移结束后会增加这个编号值，直到所有旧桶迁移完毕，把 hmap.oldbuckets 置为 nil，一次翻倍扩容结束。 如果没有超过设置的负载因子上限，但是使用的溢出桶较多，也会触发扩容，不过这一次是等量扩容 如果常规桶数目不大于 2^15，那么使用的溢出桶数目超过常规桶就算是多了； 如果常规桶数目大于 2^15，那么使用溢出桶数目一旦超过 2^15 就算多了 桶的负载因子没有超过上限值，却偏偏使用了很多溢出桶呢？因为是有很多键值对被删除的情况。 如果把这些键值对重新安排到等量的新桶中，虽然哈希值没变，常规桶数目没变，每个键值对还是会选择与旧桶一样的新桶编号，但是能够存储的更加紧凑，进而减少溢出桶的使用。 正是因为扩容过程中会发生键值对迁移，键值对的地址也会发生改变，所以才说 map 的元素是不可寻址的，如果要取一个 value 的地址则不能通过编译。map 遍历// 生成随机数 rr := uintptr(fastrand())if h.B &amp;gt; 31-bucketCntBits { r += uintptr(fastrand()) &amp;lt;&amp;lt; 31}// 从哪个 bucket 开始遍历it.startBucket = r &amp;amp; (uintptr(1)&amp;lt;&amp;lt;h.B - 1)// 从 bucket 的哪个 cell 开始遍历it.offset = uint8(r &amp;gt;&amp;gt; h.B &amp;amp; (bucketCnt - 1))例如，B = 2，那 uintptr(1)«h.B - 1 结果就是 3，低 8 位为 0000 0011，将 r 与之相与，就可以得到一个 0~3 的 bucket 序号；bucketCnt - 1 等于 7，低 8 位为 0000 0111，将 r 右移 2 位后，与 7 相与，就可以得到一个 0~7 号的 cell。首先根据 B 进行位运算得到起始 Buckets，然后与 7 进行位运算得到起始槽位 cell，然后开始进行遍历，最后再遍历当前桶槽位之前的 cell，如果是在扩容阶段则需要进行老 Buckets 是否迁移完成的判断，如果迁移完成直接进行遍历，没有进行判断是否是加倍扩容，加倍扩容则需要拿出到当前新桶的元素进行迁移，然后继续进行，知道返回起始桶的 cell 前位置。map 插入或更新对 key 计算 hash 值，根据 hash 值按照之前的流程，找到要赋值的位置（可能是插入新 key，也可能是更新老 key），对相应位置进行赋值。核心还是一个双层循环，外层遍历 bucket 和它的 overflow bucket，内层遍历整个 bucket 的各个 cell。插入的大致过程： 首先会检查 map 的标志位 flags。如果 flags 的写标志位此时被置 1 了，说明有其他协程在执行“写”操作，进而导致程序 panic。这也说明了 map 对协程是不安全的。 定位 map key 如果 map 处在扩容的过程中，那么当 key 定位到了某个 bucket 后，需要确保这个 bucket 对应的老 bucket 完成了迁移过程。即老 bucket 里的 key 都要迁移到新的 bucket 中来（分裂到 2 个新 bucket），才能在新的 bucket 中进行插入或者更新的操作。 准备两个指针，一个（inserti）指向 key 的 hash 值在 tophash 数组所处的位置，另一个(insertk)指向 cell 的位置（也就是 key 最终放置的地址），当然，对应 value 的位置就很容易定位出来了。这三者实际上都是关联的，在 tophash 数组中的索引位置决定了 key 在整个 bucket 中的位置（共 8 个 key），而 value 的位置需要“跨过” 8 个 key 的长度。 在循环的过程中，inserti 和 insertk 分别指向第一个找到的空闲的 cell。如果之后在 map 没有找到 key 的存在，也就是说原来 map 中没有此 key，这意味着插入新 key。那最终 key 的安置地址就是第一次发现的“空位”（tophash 是 empty）。 如果这个 bucket 的 8 个 key 都已经放置满了，那在跳出循环后，发现 inserti 和 insertk 都是空，这时候需要在 bucket 后面挂上 overflow bucket。当然，也有可能是在 overflow bucket 后面再挂上一个 overflow bucket。这就说明，太多 key hash 到了此 bucket。 最后，会更新 map 相关的值，如果是插入新 key，map 的元素数量字段 count 值会加 1；在函数之初设置的 hashWriting 写标志处会清零。 map 删除 它首先会检查 h.flags 标志，如果发现写标位是 1，直接 panic，因为这表明有其他协程同时在进行写操作。 计算 key 的哈希，找到落入的 bucket。检查此 map 如果正在扩容的过程中，直接触发一次搬迁操作。删除操作同样是两层循环，核心还是找到 key 的具体位置。寻找过程都是类似的，在 bucket 中挨个 cell 寻找。 找到对应位置后，对 key 或者 value 进行“清零”操作： 最后，将 count 值减 1，将对应位置的 tophash 值置成 Empty。 map 总结 无法对 map 的key 和 value 取地址 在查找、赋值、遍历、删除的过程中都会检测写标志，一旦发现写标志置位（等于1），则直接 panic。赋值和删除函数在检测完写标志是复位之后，先将写标志位置位，才会进行之后的操作。 map 的 value 本身是不可寻址的 type Student struct { Name string } func main() { student := map[string]*Student{&quot;name&quot;: {&quot;test&quot;}} student[&quot;name&quot;].Name = &quot;a&quot; fmt.Println(student[&quot;name&quot;]) } 因为 map 中的值会在内存中移动，并且旧的指针地址在 map 改变时会变得⽆效。故如果需要修改 map 值，可以将 map 中的⾮指针类型 value ，修改为指针类型，⽐如使⽤ map[string]*Student 。 student[&quot;name&quot;].Name = &quot;a&quot; 不能直接进行赋值，student[&quot;name&quot;] 返回的是两个参数，可以先通过变量接收后进行赋值修改。 map 是并发读写不安全的 type UserAges struct { ages map[string]int sync.Mutex } func (ua *UserAges) Add(name string, age int) { ua.Lock() defer ua.Unlock() ua.ages[name] = age } func (ua *UserAges) Get(name string) int { if age, ok := ua.ages[name]; ok { return age } return -1 } 在执⾏ Get ⽅法时可能被 panic。 虽然有使⽤ sync.Mutex 做写锁，但是 map 是并发读写不安全的。map 属于引⽤类型，并发读写时多个协程⻅是通过指针访问同⼀个地址，即访问共享变量，此时同时读写资源存在竞争关系。会报错误信息:“fatal error: oncurrent map read and map write”。 因此，在 Get 中也需要加锁，因为这⾥只是读，建议使⽤读写 sync.RWMutex 。 sync.map 没有 len 方法 无法对 map 的 key 或 value 进行取址 package main import &quot;fmt&quot; func main() { m := make(map[string]int) fmt.Println(&amp;amp;m[&quot;qcrao&quot;]) } // main.go:8:14: cannot take the address of m[&quot;qcrao&quot;]如果通过其他 hack 的方式，例如 unsafe.Pointer 等获取到了 key 或 value 的地址，也不能长期持有，因为一旦发生扩容，key 和 value 的位置就会改变，之前保存的地址也就失效了。 删除 map 不存在的键值对时，不会报错，相当于没有任何作用 获取不存在的键值对时，返回值类型对应的零值，所以返回 0" }, { "title": "Slice", "url": "/posts/slice/", "categories": "Go, Slice", "tags": "Go", "date": "2022-03-15 21:00:00 +0800", "snippet": "slice 底层结构切片在运行时的表现是 SliceHeader 结构体，定义如下：type SliceHeader struct { Data uintptr Len int Cap int} Data：指向具体的底层数组。 Len：代表切片的长度。 Cap：代表切片的容量。要点是：切片真正存储数据的地方，是一个数组。切片的 Data 属性中存储的是指向所引用的数组指针地址。可以将切片理解成一片连续的内存空间加上长度与容量的标识.初始化切片 arr := arr[1:3] // 下标 arr := []int{1, 2, 3} // 字面量 arr := make([]int, 2, 3) // 关键字 使用下标初始化切片 不会拷贝原数组或者原切片中的数据，它只会创建一个指向原数组的切片结构体，所以修改新切片的数据也会修改原切片。 字面量初始化切片 是在编译时完成的。 根据切片中的元素数量对底层数组的大小进行推断并创建一个数组 将这些字面量元素存储到初始化的数组中 创建一个同样指向 [3]int 类型的数组指针 将静态存储区的数组 vstat 赋值给 vauto 指针所在的地址 通过 [:] 操作获取一个底层使用 vauto 的切片 关键字 创建切片时，很多工作都需要运行时的参与。不仅会检查 len 是否传入，还会保证传入的容量 cap 一定大于或者等于 len。当切片发生逃逸或者非常大时，运行时需要 runtime.makeslice 在堆上初始化切片，如果当前的切片不会发生逃逸并且切片非常小的时候，会直接使用下标得到得到数组对应的切片。整形切片var ints []intslice 的元素要存在连续的内存中，也就是连续数组。 data 是底层数组的起始地址,这里只分配了切片结构没有分配底层数组，此时 data = nil，Len 和 Cap 都为零。var arr []int = make([]int, 2, 5)arr = append(arr, 1)arr[0] = 1通过 make 的方式定义变量，不仅会分配结构还会开辟一段内存作为它的底层数组。此时分配的值都为 0。通过 append 之后此时索引 2 的位置被修改为 1，通过索引下标 0 修改后第一个元素为 1， 其他位置还是默认值 0。字符串类型切片arr := new([]string)*arr = append(*arr, &quot;kevin&quot;)// append(arr, &quot;kevin&quot;) 会报错// invalid argument: arr (variable of type *[]string) is not a slicecompiler// 因为 new 返回的是指针起始地址上面 new 一个 slice 对象同样会分配切片的三部分，它不负责底层数组的分配，new 的返回值是 slice 的指针地址，如果这时候 (*arr)[0] = &quot;kevin&quot; 通过下标修改切片内容是不允许的，此时可以通过 append 进行分配底层数组。和字符串相关的底层数组底层数组是相同类型的元素一个挨一个的存储，不同的slice 可以关联到同一个数组。slice 的 data 起始指针并不一定指向数组的开头，如下例：arr := [10]int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}var s1 = arr[1:4]var s2 = arr[7:]s1 的元素是 arr 索引 1到4 的元素，左闭又开，长度是 3，但是容量 Cap 是从索引 1 开始到末尾 为 9，s2 的元素是从 索引 7 到末尾，总共三个元素容量 Cap 也是 3。slice 访问和修改的都是底层数组的元素。s1[3] = 5上面 s1 就会越界产生 panic，只能扩大读写区间范围。此时如果给 s2 添加元素 s2 = append(s2, 10) 会开辟新数组，原来的元素要拷过来同时添加新元素，元素个数改为 4，容量扩到 6。扩容规则如果 append 返回的新切片不需要赋值回原有的变量，就会 makeslice 创建一个新的 slice；如果使用 slice = append(slice, 1, 2, 3) 语句，那么 append 后的切片会覆盖原切片。// append(slice, 1, 2, 3)ptr, len, cap := slicenewlen := len + 3if newlen &amp;gt; cap { ...}*(ptr+len) = 1*(ptr+len+1) = 2*(ptr+len+2) = 3return makeslice(ptr, newlen, cap)// slice = append(slice, 1, 2, 3)a := &amp;amp;slice... // 同上if uint(newlen) &amp;gt; uint(cap) { *a.cap = newcap *a.ptr = newptr}newlen = len + 3*a.len = newlen*(ptr+len) = 1*(ptr+len+1) = 2*(ptr+len+2) = 3预估容量arr := []int{1, 2}arr = append(arr, 3, 4, 5)上面扩容后容量到 5，因为整形元素占有 8 字节，根据内存规格匹配到 48 。下面分析为什么？在分配内存空间之前需要先确定新的切片容量，运行时根据切片的当前容量选择不同的策略进行扩容： 如果期望容量大于当前容量的两倍就会使用期望容量（也就是当前容量翻倍） 如果当前切片的长度小于 1024 就会将容量翻倍 如果当前切片的长度大于 1024 就会每次增加 25% 的容量，直到新容量大于期望容量内存分配内存空间=切片中元素大小×目标容量。语言的内存管理模块会提前向操作系统申请一批内存，分成常用规格管理起来。当申请内存时会匹配合适的规格进行分配。var class_to_size = [_NumSizeClasses]uint16{ 0, 8, 16, 32, 48, 64, 80, ...,}例子如下：a := []string{&quot;my&quot;, &quot;name&quot;, &quot;is&quot;}a = append(a, &quot;kevin&quot;) 字符串在 64 位机器上每个元素占 16 字节，扩容前容量是 3，添加一个最少扩容到4，原容量翻倍等于 6 大于 4，小于1024，直接翻倍预估容量为 6。 预估容量元素大小（616=96byte） 匹配到内存规格 96 所以最终扩容后容量为 6切片 copy无论是编译期间拷贝还是运行时拷贝，两种拷贝方式都会通过 runtime.memmove 将整块内存的内容拷贝到目标的内存区域中。Classic problems2 := s1[2:6:7]长度 s2 从 s1 的索引2（闭区间）到索引6（开区间，元素真正取到索引5），容量到索引7（开区间，真正到索引6），为5。…Go 提供的语法糖 ...，可以将 slice 传进可变函数，不会创建新的切片func main() { slice := make([]int, 5, 5) slice[0] = 1 slice[1] = 2 // 此处因为 append 操作底层数组发生了扩容，原 slice 的底层数组不会改变 change(slice...) fmt.Println(slice) // [1, 2, 0, 0, 0] // 此处 [0:2] 截取获得一个新切片，长度为 2， 容量为 5 // 在 append 操作中原切片底层数据容量足够，不会发生扩容，影响到原切片的长度 change(slice[0:2]...) fmt.Println(slice) // [1, 2, 3, 0, 0]}func change(s ...int) { s = append(s, 3) fmt.Println(s)}Len and cap Go 语言中的所有东西都是以值传递的。也就是说，一个函数总是得到一个被传递的东西的副本，就像有一个赋值语句将值赋给参数一样。如果传过去的值是指向内存空间的地址，是可以对这块内存空间做修改的。func main() { sl := make([]int, 0, 10) var appenFunc = func(s []int) { s = append(s, 10, 20, 30) fmt.Println(s) } fmt.Println(sl) appenFunc(sl) fmt.Println(sl) fmt.Println(sl[:10]) fmt.Println(sl[:])}实质上在调用 appenFunc(sl) 函数时，实际上修改了底层所指向的数组，自然也就会发生变化，也就不难理解为什么 10, 20, 30 元素会出现了常用的访问切片我们会用：s[low : high]注意这里是：low 、high 。没有用 len cap 这种定性的词语，也就代表着这里的取值是可变的。当是切片（slice）时，表达式 s[low : high] 中的 high，最大的取值范围对应着切片的容量cap，不是单纯的长度len。因此调用 fmt.Println(sl[:10]) 时可以输出容量范围内的值，不会出现越界。相对的 fmt.Println(sl[:]) 因为该切片 len 值为 0，没有指定最大索引值，high 则取 len 值，导致输出结果为空。slice 的泄漏var a []intfunc f(b []int) []int { a = b[:2] return a}func main() { ...}// 切片 a 和 b 都共享着同一个底层数组（共享内存块），sliceB 包含全部所引用的字符。sliceA 只包含了 [:2]，也就是 0 和 1 两个索引位的字符。泄露的点 就在于虽然切片 b 已经在函数内结束了他的使命了，不再使用了。但切片 a 还在使用，切片 a 和 切片 b 引用的是同一块底层数组（共享内存块）。虽然切片 a 只有底层数组中 0 和 1 两个索引位正在被使用，其余未使用的底层数组空间毫无作用。但由于正在被引用，他们也不会被 GC，因此造成了泄露。解决办法利用切片的特性。当切片的容量空间不足时，会重新申请一个新的底层数组来存储，让两者彻底分手。var a []intvar c []int // 第三者func f(b []int) []int { a = b[:2] // 新的切片 append 导致切片扩容 c = append(c, b[:2]...) fmt.Printf(&quot;a: %p\\nc: %p\\nb: %p\\n&quot;, &amp;amp;a[0], &amp;amp;c[0], &amp;amp;b[0]) return a}" }, { "title": "Go 常见面试题", "url": "/posts/go-interview/", "categories": "Go, Interview", "tags": "面试, Go", "date": "2022-02-08 09:30:00 +0800", "snippet": "Go - nilnil 只能赋值给指针、chan、func、interface、map 或 slice 类型的变量channelGo 语言中，不要通过共享内存来通信，而要通过通信来实现内存共享。Go 的 CSP(Communicating Sequential Process)并发模型，中文叫做通信顺序进程，是通过 goroutine 和 channel 来实现的。channel 收发遵循先进先出 FIFO，分为有缓存和无缓存，channel 中大致有 buffer(当缓冲区大小部位 0 时，是个 ring buffer)、sendx 和 recvx 收发的位置(ring buffer 记录实现)、sendq、recvq 当前 channel 因为缓冲区不足而阻塞的队列、使用双向链表存储、还有一个 mutex 锁控制并发、其他原属等。向通道发送数据func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { lock(&amp;amp;c.lock) if c.closed != 0 { unlock(&amp;amp;c.lock) panic(plainError(&quot;send on closed channel&quot;)) }在发送数据的逻辑执行之前会先为当前 Channel 加锁，防止多个线程并发修改数据。如果 Channel 已经关闭，那么向该 Channel 发送数据时会报 “send on closed channel” 错误并中止程序。执行过程分成以下的三个部分： 当存在等待的接收者时，通过 runtime.send 直接将数据发送给阻塞的接收者； 当缓冲区存在空余空间时，将发送的数据写入 Channel 的缓冲区； 当不存在缓冲区或者缓冲区已满时，等待其他 Goroutine 从 Channel 接收数据；发送数据 如果当前 Channel 的 recvq 上存在已经被阻塞的 Goroutine，那么会直接将数据发送给当前 Goroutine 并将其设置成下一个运行的 Goroutine，也就是将接收方的 Goroutine 放到了处理器的 runnext 中，程序没有立刻执行该 Goroutine 向一个非缓冲型的 channel 发送数据、从一个无元素的（非缓冲型或缓冲型但空）的 channel 接收数据，都会导致一个 goroutine 直接操作另一个 goroutine 的栈, 由于 GC 假设对栈的写操作只能发生在 goroutine 正在运行中并且由当前 goroutine 来写, 所以这里实际上违反了这个假设。可能会造成一些问题，所以需要用到写屏障来规避 如果 Channel 存在缓冲区并且其中还有空闲的容量，我们会直接将数据存储到缓冲区 sendx 所在的位置上； 如果不满足上面的两种情况，会创建一个 runtime.sudog 结构并将其加入 Channel 的 sendq 队列中，当前 Goroutine 也会陷入阻塞等待其他的协程从 Channel 接收数据；接收数据func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { if c == nil { if !block { return } gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(&quot;unreachable&quot;) } lock(&amp;amp;c.lock) if c.closed != 0 &amp;amp;&amp;amp; c.qcount == 0 { unlock(&amp;amp;c.lock) if ep != nil { typedmemclr(c.elemtype, ep) } return true, false }当我们从一个空 Channel 接收数据时会直接调用 runtime.gopark 让出处理器的使用权。使用 runtime.chanrecv 从 Channel 接收数据时还包含以下三种不同情况： 当存在等待的发送者时，通过 runtime.recv 从阻塞的发送者或者缓冲区中获取数据； 当缓冲区存在数据时，从 Channel 的缓冲区中接收数据； 当缓冲区中不存在数据时，等待其他 Goroutine 向 Channel 发送数据；直接接收数据时根据缓冲区的大小分别处理不同的情况： 如果 Channel 不存在缓冲区； 调用 runtime.recvDirect 将 Channel 发送队列中 Goroutine 存储的 elem 数据拷贝到目标内存地址中； 如果 Channel 存在缓冲区； 将队列中的数据拷贝到接收方的内存地址； 将发送队列头的数据拷贝到缓冲区中，释放一个阻塞的发送方； 无论发生哪种情况，运行时都会调用 runtime.goready 将当前处理器的 runnext 设置成发送数据的 Goroutine，在调度器下一次调度时将阻塞的发送方唤醒。从通道接收数据 如果 Channel 为空，那么会直接调用 runtime.gopark 挂起当前 Goroutine； 如果 Channel 已经关闭并且缓冲区没有任何数据，runtime.chanrecv 会直接返回； 如果 Channel 的 sendq 队列中存在挂起的 Goroutine，会将 recvx 索引所在的数据拷贝到接收变量所在的内存空间上并将 sendq 队列中 Goroutine 的数据拷贝到缓冲区； 如果 Channel 的缓冲区中包含数据，那么直接读取 recvx 索引对应的数据； 在默认情况下会挂起当前的 Goroutine，将 runtime.sudog 结构加入 recvq 队列并陷入休眠等待调度器的唤醒；触发调度时机 发送数据时 发送数据时发现 Channel 上存在等待接收数据的 Goroutine，立刻设置处理器的 runnext 属性，但是并不会立刻触发调度； 发送数据时并没有找到接收方并且缓冲区已经满了，这时会将自己加入 Channel 的 sendq 队列并调用 runtime.goparkunlock 触发 Goroutine 的调度让出处理器的使用权； 从 Channel 接收数据时，会触发 Goroutine 调度的两个时机： 当 Channel 为空时； 当缓冲区中不存在数据并且也不存在数据的发送者时； channel 最佳实践 读已经关闭的 chan 能⼀直读到东⻄，但是读到的内容根据通道内关闭前是否有元素⽽不同。 如果 chan 关闭前，buffer 内有元素还未读, 会正确读到 chan 内的值，且返回的第⼆个 bool 值（是否读成功）为 true。 如果 chan 关闭前，buffer 内有元素已经被读完，chan 内⽆值，接下来所有接收的值都会⾮阻塞直接成功，返回 channel 元素的零值，但是第⼆个 bool 值⼀直为 false。 触发 panic 的情况 向已经关闭的 chan 发送数据会 panic 关闭一个 nil 的 channel； 重复关闭一个 channel。 向 nil 的通道发送或接收数据会调用 gopark 挂起，并陷入永久阻塞 channel 泄漏 泄漏的原因是 goroutine 操作 channel 后，处于发送或接收阻塞状态，而 channel 处于满或空的状态，一直得不到改变。同时，垃圾回收器也不会回收此类资源，进而导致 gouroutine 会一直处于等待队列中，不见天日。runtime 包中的常用方法 NumCPU: 返回当前系统的 CPU 核数量 GOMAXPROCS: 设置最大的可同时使用的 CPU 核数 通过 runtime.GOMAXPROCS 函数，应用程序何以在运行期间设置运行时系统中得 P 最大数量。但这会引起 “Stop the World”。所以，应在应用程序最早的调用。并且最好是在运行Go程序之前设置好操作程序的环境变量 GOMAXPROCS，而不是在程序中调用 runtime.GOMAXPROCS 函数。 无论我们传递给函数的整数值是什么值，运行时系统的P最大值总会在1~256之间。 Gosched:让当前线程让出 cpu 以让其它线程运行,它不会挂起当前线程，因此当前线程未来会继续执行 这个函数的作用是让当前 goroutine 让出 CPU，当一个 goroutine 发生阻塞，Go 会自动地把与该 goroutine 处于同一系统线程的其他 goroutine 转移到另一个系统线程上去，以使这些 goroutine 不阻塞。 Goexit: 退出当前 goroutine(但是defer语句会照常执行) NumGoroutine: 返回正在执行和排队的任务总数 runtime.NumGoroutine 函数在被调用后，会返回系统中的处于特定状态的 Goroutine 的数量。这里的特指是指 Grunnable\\Gruning\\Gsyscall\\Gwaition。处于这些状态的 Groutine 即被看做是活跃的或者说正在被调度。注意：垃圾回收所在 Groutine 的状态也处于这个范围内的话，也会被纳入该计数器。 GOOS: 目标操作系统 GC: 会让运行时系统进行一次强制性的垃圾收集 1.强制的垃圾回收：不管怎样，都要进行的垃圾回收。2.非强制的垃圾回收：只会在一定条件下进行的垃圾回收（即运行时，系统自上次垃圾回收之后新申请的堆内存的单元（也成为单元增量）达到指定的数值）。 GOROOT: 获取 goroot 目录 GOOS: 查看目标操作系统垃圾回收追踪式标记清除GC 的根对象是什么？ 全局变量：程序在编译期就能确定的那些存在于程序整个生命周期的变量。 执行栈：每个 goroutine 都包含自己的执行栈，这些执行栈上包含栈上的变量及指向分配的堆内存区块的指针。 寄存器：寄存器的值可能表示一个指针，参与计算的这些指针可能指向某些赋值器分配的堆内存区块。三色标记 三色抽象只是一种描述追踪式回收器的方法，在实践中并没有实际含义，它的重要作用在于从逻辑上严密推导标记清理这种垃圾回收方法的正确性。垃圾回收器的视角来看，三色抽象规定了三种不同类型的对象，并用不同的颜色相称： 白色对象（可能死亡）：未被回收器访问到的对象。在回收开始阶段，所有对象均为白色，当回收结束后，白色对象均不可达。 灰色对象（波面）：已被回收器访问到的对象，但回收器需要对其中的一个或多个指针进行扫描，因为他们可能还指向白色对象。 黑色对象（确定存活）：已被回收器访问到的对象，其中所有字段都已被扫描，黑色对象中任何一个指针都不可能直接指向白色对象。这样三种不变性所定义的回收过程其实是一个波面不断前进的过程，这个波面同时也是黑色对象和白色对象的边界，灰色对象就是这个波面。悬挂指针，即指针没有指向特定类型的合法对象，影响了内存的安全性，想要并发或者增量地标记对象还是需要使用屏障技术。屏障技术 强三色不变性 — 黑色对象不会指向白色对象，只会指向灰色对象或者黑色对象 弱三色不变性 — 黑色对象指向的白色对象必须包含一条从灰色对象经由多个白色对象的可达路径插入写屏障writePointer(slot, ptr): shade(ptr) *slot = ptrDijkstra 的插入写屏障是一种相对保守的屏障技术，它会将有存活可能的对象都标记成灰色以满足强三色不变性。垃圾收集和用户程序交替运行时将黑色对象 A 指向白色对象 B，会将对象 B 标记成灰色，完成插入写屏障也就满足了强三色不变性。插入式的 Dijkstra 写屏障虽然实现非常简单并且也能保证强三色不变性，但是它也有明显的缺点。因为栈上的对象在垃圾收集中也会被认为是根对象，所以为了保证内存的安全，Dijkstra 必须为栈上的对象增加写屏障或者在标记阶段完成重新对栈上的对象进行扫描，这两种方法各有各的缺点，前者会大幅度增加写入指针的额外开销，后者重新扫描栈对象时需要暂停程序，垃圾收集算法的设计者需要在这两者之间做出权衡。删除写屏障会在老对象的引用被删除时，将白色的老对象涂成灰色，这样删除写屏障就可以保证弱三色不变性，老对象引用的下游对象一定可以被灰色对象引用。垃圾收集和用户程序交替运行时黑色对象 A 指向灰色对象 B，B 指向白色对象 C，此时 A 指向 C，因为灰色对象 B 指向白色对象 C，此时不触发删除写屏障，如果将灰色对象 B 原本指向白色对象 C 的指针删除，会将对象 C 标记成灰色，完成删除写屏障也就满足了强/弱三色不变性。混合写屏障在 Go 语言 v1.7 版本之前，运行时会使用 Dijkstra 插入写屏障保证强三色不变性，但是运行时并没有在所有的垃圾收集根对象上开启插入写屏障。因为应用程序可能包含成百上千的 Goroutine，而垃圾收集的根对象一般包括全局变量和栈对象，如果运行时需要在几百个 Goroutine 的栈上都开启写屏障，会带来巨大的额外开销，所以 Go 团队在实现上选择了在标记阶段完成时暂停程序、将所有栈对象标记为灰色并重新扫描，在活跃 Goroutine 非常多的程序中，重新扫描的过程需要占用 10 ~ 100ms 的时间。会将被覆盖的对象标记成灰色并在当前栈没有扫描时将新对象也标记成灰色。为了移除栈的重扫描过程，除了引入混合写屏障之外，在垃圾收集的标记阶段，我们还需要将创建的所有新对象都标记成黑色，防止新分配的栈内存和堆内存中的对象被错误地回收，因为栈内存在标记阶段最终都会变为黑色，所以不再需要重新扫描栈空间。增量和并发 增量垃圾收集 — 增量地标记和清除垃圾，降低应用程序暂停的最长时间 增量式（Incremental）的垃圾收集是减少程序最长暂停时间的一种方案，它可以将原本时间较长的暂停时间切分成多个更小的 GC 时间片，虽然从垃圾收集开始到结束的时间更长了，但是这也减少了应用程序暂停的最大时间； 为了保证垃圾收集的正确性，我们需要在垃圾收集开始前打开写屏障，这样用户程序修改内存都会先经过写屏障的处理，保证了堆内存中对象关系的强三色不变性或者弱三色不变性。虽然增量式的垃圾收集能够减少最大的程序暂停时间，但是增量式收集也会增加一次 GC 循环的总时间，在垃圾收集期间，因为写屏障的影响用户程序也需要承担额外的计算开销，所以增量式的垃圾收集也不是只带来好处的，但是总体来说还是利大于弊。 并发垃圾收集 — 利用多核的计算资源，在用户程序执行时并发标记和清除垃圾 并发（Concurrent）的垃圾收集不仅能够减少程序的最长暂停时间，还能减少整个垃圾收集阶段的时间，通过开启读写屏障、利用多核优势与用户程序并行执行，并发垃圾收集器确实能够减少垃圾收集对应用程序的影响 虽然并发收集器能够与用户程序一起运行，但是并不是所有阶段都可以与用户程序一起运行，部分阶段还是需要暂停用户程序的，不过与传统的算法相比，并发的垃圾收集可以将能够并发执行的工作尽量并发执行；当然，因为读写屏障的引入，并发的垃圾收集器也一定会带来额外开销，不仅会增加垃圾收集的总时间，还会影响用户程序，这是我们在设计垃圾收集策略时必须要注意的。 垃圾收集的阶段 清理终止阶段 STW 暂停程序，所有的处理器在这时会进入安全点（Safe point）； 如果当前垃圾收集循环是强制触发的，我们还需要处理还未被清理的内存管理单元； 标记阶段 将状态切换至 _GCmark、开启写屏障、用户程序协助（Mutator Assists）并将根对象入队； 恢复执行程序，标记进程和用于协助的用户程序会开始并发标记内存中的对象，写屏障会将被覆盖的指针和新指针都标记成灰色，而所有新创建的对象都会被直接标记成黑色； 开始扫描根对象，包括所有 Goroutine 的栈、全局对象以及不在堆中的运行时数据结构，扫描 Goroutine 栈期间会暂停当前处理器； 依次处理灰色队列中的对象，将对象标记成黑色并将它们指向的对象标记成灰色； 使用分布式的终止算法检查剩余的工作，发现标记阶段完成后进入标记终止阶段； 标记终止阶段 STW 暂停程序、将状态切换至 _GCmarktermination 并关闭辅助标记的用户程序； 清理处理器上的线程缓存； 清理阶段 将状态切换至 _GCoff 开始清理阶段，初始化清理状态并关闭写屏障； 恢复用户程序，所有新创建的对象会标记成白色； 后台并发清理所有的内存管理单元，当 Goroutine 申请新的内存管理单元时就会触发清理 runtime.work 变量：该结构体中包含大量垃圾收集的相关字段，例如：表示完成的垃圾收集循环的次数、当前循环时间和 CPU 的利用率、垃圾收集的模式等等，我们会在后面的小节中见到该结构体中的更多字段。GC 触发时机Go 语言中对 GC 的触发时机存在两种形式： 主动触发，通过调用 runtime.GC 来触发 GC，此调用阻塞式地等待当前 GC 运行完毕。 被动触发，分为两种方式： 使用系统监控，如果一定时间内没有触发，就会触发新的循环，该触发条件由 runtime.forcegcperiod 变量控制，默认为 2 分钟； 使用步调（Pacing）算法，其核心思想是控制内存增长的比例。 申请内存 最后一个可能会触发垃圾收集的就是 runtime.mallocgc 了，我们在上一节内存分配器中曾经介绍过运行时会将堆上的对象按大小分成微对象、小对象和大对象三类，这三类对象的创建都可能会触发新的垃圾收集循环： 当前线程的内存管理单元中不存在空闲空间时，创建微对象和小对象需要调用 runtime.mcache.nextFree 从中心缓存或者页堆中获取新的管理单元，在这时就可能触发垃圾收集； 当用户程序申请分配 32KB 以上的大对象时，一定会构建 runtime.gcTrigger 结构体尝试触发垃圾收集； 通过堆内存触发垃圾收集需要比较 runtime.mstats 中的两个字段 — 表示垃圾收集中存活对象字节数的 heap_live 和表示触发标记的堆内存大小的 gc_trigger；当内存中存活的对象字节数大于触发垃圾收集的堆大小时，新一轮的垃圾收集就会开始。在这里，我们将分别介绍这两个值的计算过程： heap_live — 为了减少锁竞争，运行时只会在中心缓存分配或者释放内存管理单元以及在堆上分配大对象时才会更新； gc_trigger — 在标记终止阶段调用 runtime.gcSetTriggerRatio 更新触发下一次垃圾收集的堆大小； GC 如何调优 通过 go tool pprof 和 go tool trace 等工具 控制内存分配的速度，限制 goroutine 的数量，从而提高赋值器对 CPU 的利用率。 减少并复用内存，例如使用 sync.Pool 来复用需要频繁创建临时对象，例如提前分配足够的内存来降低多余的拷贝。 需要时，增大 GOGC 的值，降低 GC 的运行频率。GC 跟不上分配的速度目前的 Go 实现中，当 GC 触发后，会首先进入并发标记的阶段。并发标记会设置一个标志，并在 mallocgc 调用时进行检查。当存在新的内存分配时，会暂停分配内存过快的那些 goroutine，并将其转去执行一些辅助标记（Mark Assist）的工作，从而达到放缓继续分配、辅助 GC 的标记工作的目的。内存分配内存逃逸逃逸分析最基本的原则: 编译器会分析代码的特征和代码生命周期，Go 中的变量只有在编译器可以证明在函数返回后不会再被引用的，才分配到栈上，其他情况下都是分配到堆上。引起变量逃逸到堆上的典型情况： 在⽅法内把局部变量指针返回, 局部变量原本应该在栈中分配，在栈中回收。但是由于返回时被外部引⽤，因此其⽣命周期⼤于栈，则溢出。 发送指针或带有指针的值到 channel 中。在编译时，是没有办法知道哪个 goroutine 会在 channel 上接收数据。所以编译器没法知道变量什么时候才会被释放。 在⼀个切⽚上存储指针或带指针的值。⼀个典型的例⼦就是 []*string。这会导致切⽚的内容逃逸。尽管其后⾯的数组可能是在栈上分配的，但其引⽤的值⼀定是在堆上。 slice 的背后数组被重新分配了，因为 append 时可能会超出其容量(cap)。slice 初始化的地⽅在编译时是可以知道的，它最开始会在栈上分配。如果切⽚背后的存储要基于运⾏时的数据进⾏扩充，就会在堆上分配。 在 interface 类型上调⽤⽅法。在 interface 类型上调⽤⽅法都是动态调度的⽅法的真正实现只能在运⾏时知道。想像⼀个 io.Reader 类型的变量 r , 调⽤ r.Read(b) 会使得 r 的值和切⽚ b 的背后存储都逃逸掉，所以会在堆上分配。 闭包的捕获变量也会分配到堆上，还有就是大对象 大于 32KBnew 一个对象最后在堆上还是栈上就根据上面的逃逸分析进行回答deferdefer 关键字的实现跟 go 关键字很类似，不同的是它调⽤的是 runtime.deferproc ⽽不是 runtime.newproc。 在 defer 出现的地⽅，插⼊了指令 call runtime.deferproc，然后在函数返回之前的地⽅，插⼊指令 call runtime.deferreturn。 goroutine 的控制结构中，有⼀张表记录 defer，调⽤ runtime.deferproc 时会将需要 defer 的表达式记录在表中，⽽在调⽤ runtime.deferreturn 的时候，则会依次从 defer 表中出栈并执⾏。因此，题⽬最后输出顺序应该是 defer 定义顺序的倒序。 panic 错误并不能终⽌ defer 的执⾏。继承与多态type People interface { Speak(string) string}type Stduent struct{}func (stu *Stduent) Speak(think string) (talk string) { if think == &quot;love&quot; { talk = &quot;You are a good boy&quot; } else { talk = &quot;hi&quot; } return}func main() { var peo People = Stduent{} think := &quot;love&quot; fmt.Println(peo.Speak(think))}在 golang 中对多态的特点体现从语法上并不是很明显。我们知道发生多态的几个要素： 有 interface 接口，并且有接口定义的方法。 有子类去重写 interface 的接口。 有父类指针指向子类的具体对象那么，满足上述 3 个条件，就可以产生多态效果，就是，父类指针可以调用子类的具体方法。所以上述代码报错的地方在 var peo People = Stduent{} 这条语句， Student{} 已经重写了父类 People{} 中的 Speak(string) string 方法，那么只需要用父类指针指向子类对象即可。（Go 中不叫父类，这里是为了好理解）所以应该改成 var peo People = &amp;amp;Student{} 即可编译通过。（People 为 interface 类型，就是指针类型）" }, { "title": "Redis 常见面试题", "url": "/posts/redis-interview/", "categories": "Redis, Interview", "tags": "面试, Redis", "date": "2022-01-20 09:50:00 +0800", "snippet": "Redis 为什么这么快？ 纯内存操作 不论读写操作都是在内存上完成的，跟传统的磁盘文件数据存储相比，避免了通过磁盘 IO 读取到内存这部分的开销。 单线程模型 避免了频繁的上下文切换和竞争锁机制，也不会出现频繁切换线程导致CPU消耗，不会存在多线程的死锁等一系列问题。 单线程指的是 Redis 键值对读写请求的执行是单线程。Redis 服务在执行一些其他命令时就会使用多线程，对于 Redis 的持久化、集群数据同步、异步删除的指令如 UNLINK、FLUSHALL ASYNC、FLUSHDB ASYNC 等非阻塞的删除操作。 I/O 多路复用模型 Redis 采用 I/O 多路复用技术，并发处理连接。 Redis 作为一个内存服务器，它需要处理很多来自外部的网络请求，它使用 I/O 多路复用机制同时监听多个文件描述符的可读和可写状态，一旦受到网络请求就会在内存中快速处理，由于绝大多数的操作都是纯内存的，所以处理的速度会非常地快。 高效的数据结构 redis 共有 string、list、hash、set、sortedset 五种数据机构 SDS 简单动态字符串 1 .SDS 中 len 保存这字符串的长度，O(1) 时间复杂度查询字符串长度信息。 2 .空间预分配：SDS 被修改后，程序不仅会为 SDS 分配所需要的必须空间，还会分配额外的未使用空间。 3 .惰性空间释放：当对 SDS 进行缩短操作时，程序并不会回收多余的内存空间，而是使用 free 字段将这些字节数量记录下来不释放，后面如果需要 append 操作，则直接使用 free 中未使用的空间，减少了内存的分配。 zipList 压缩列表 压缩列表是 List 、hash、 sorted Set 三种数据类型底层实现之一。 当一个列表只有少量数据的时候，并且每个列表项要么就是小整数值，要么就是长度比较短的字符串，那么 Redis 就会使用压缩列表来做列表键的底层实现。 quicklist 首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是 ziplist，也就是压缩列表。 它将所有的元素紧挨着一起存储，分配的是一块连续的内存。当数据量比较多的时候才会改成 quicklist。 因为普通的链表需要的附加指针空间太大，会比较浪费空间，而且会加重内存的碎片化。 skipList 跳跃表 sorted set 类型的排序功能便是通过「跳跃列表」数据结构来实现。 跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。 跳表在链表的基础上，增加了多层级索引，通过索引位置的几个跳转，实现数据的快速定位 IntSet 小整数集合 当 set 集合容纳的元素都是整数并且元素个数较小时，Redis 会使用 intset 来存储结合元素。intset 是紧凑的数组结构，同时支持 16 位、32 位和 64 位整数。 简单的 RESP 通信协议 RESP 是 Redis 序列化协议的简写。它是一种直观的文本协议，优势在于实现异常简单，解析性能极好。 Redis 协议将传输的结构数据分为 5 种最小单元类型，单元结束时统一加上回车换行符号 \\r\\n。 1.单行字符串以 + 符号开头。 2.多行字符串 以 $ 符号开头，后跟字符串长度。 3.整数值以 : 符号开头，后跟整数的字符串形式。 4.错误消息以 - 符号开头。 5.数组以 * 号开头，后跟数组的长度。 为什么选择单线程？ 使用单线程模型能带来更好的可维护性，方便开发和调试 使用单线程模型也能并发的处理客户端的请求 Redis 服务中运行的绝大多数操作的性能瓶颈都不是 CPUredis 与 memcache 比有什么优势？ 数据类型：memcached 只支持以 key-value 形式访问存取数据，在内存中维护一张巨大的哈希表，从而保证所有查询的时间复杂度是 O(1)；redis 则支持除 key-value 之外的其他数据类型，比如 list、set、hash、zset 等，用来实现队列、有序集合等更复杂的功能； 性能：memcached 支持多线程，可以利用多核优势，不过也引入了锁，redis 是单线程，在操作大数据方面，memcached 更有优势，处理小数据的时候，redis 更优； 数据持久化：redis 支持数据同步和持久化存储，memcached 不支持，意味着一旦机器重启所有存储数据将会丢失； 数据一致性：memcached 提供了 cas 命令来保证，而 redis 提供了事务的功能，可以保证一串命令的原子性，中间不会被任何操作打断 。 分布式：memcached 本身不支持分布式存储，只能在客户端通过一致性哈希算法实现，属于客户端实现；redis 更倾向于在服务端构建分布式存储，并且 redis 本身就对此提供了支持，即redis cluster。Redis 基础数据类型和结构所有的 Redis 对象都有下面这个对象头结构：struct RedisObject { int4 type; // 4bits int4 encoding; // 4bits int24 lru; // 24bits int32 refcount; // 4bytes void *ptr; // 8bytes，64-bit system} robj;不同的对象具有不同的类型 type(4bit)，同一个类型的 type 会有不同的存储形式 encoding(4bit)，为了记录对象的 LRU 信息，使用了 24 个 bit 来记录 LRU 信息。每个对象都有个引用计数，当引用计数为零时，对象就会被销毁，内存被回收。ptr 指针将指向对象内容 (body) 的具体存储位置。这样一个 RedisObject 对象头需要占据 16 字节的存储空间。String 字符串类型基础介绍字符串结构使用非常广泛，一个常见的用途就是缓存用户信息、锁、计数器和限速器等。如果 value 值是一个整数，还可以对它进行自增操作。自增是有范围的，它的范围是 signed long 的最大最小值，超过了这个值，Redis 会报错。Redis 规定字符串的长度不得超过 512M 字节。常用命令&amp;gt; set name Jugg OK&amp;gt; exists name # 是否存在(integer) 1&amp;gt; del name # 删除(integer) 1&amp;gt; get name(nil)# 批量操作&amp;gt; mset name1 boy name2 girl name3 unknown&amp;gt; mget name1 name2 name3 # 返回一个列表1) &quot;Jugg&quot;2) &quot;holycoder&quot;3) (nil)// 过期&amp;gt; expire name 5 # 5s 后过期&amp;gt; get name # wait for 5s(nil)&amp;gt; ttl name-1&amp;gt; set age 30OK&amp;gt; incr age(integer) 31&amp;gt; incrby age 5(integer) 36&amp;gt; incrby age -5(integer) 31&amp;gt; set codehole 9223372036854775807 # Long.MaxOK&amp;gt; incr codehole(error) ERR increment or decrement would overflow&amp;gt; setex name 5 Jugg # 5s 后过期，等价于 set+expire&amp;gt; setnx name Jugg # 如果 name 不存在就执行 set 创建，如果已经存在，set 创建不成功(integer) 1 / 0&amp;gt; get name&quot;Jugg&quot;// set 指令扩展&amp;gt; set lock:Jugg true ex 5 nxOK底层结构struct SDS&amp;lt;T&amp;gt; { T capacity; // 数组容量 T len; // 数组长度 byte flags; // 特殊标识位，不理睬它 byte[] content; // 数组内容}Redis 的字符串是动态字符串，是可以修改的字符串，采用预分配冗余空间的方式来减少内存的频繁分配，内部为当前字符串实际分配的空间 capacity 一般要高于实际字符串长度 len。但是 Redis 创建字符串时 len 和 capacity 一样长，不会多分配冗余空间，这是因为绝大多数场景下我们不会使用 append 操作来修改字符串。上面的 SDS 结构使用了范型 T，为什么不直接用 int 呢，这是因为当字符串比较短时，len 和 capacity 可以使用 byte 和 short 来表示，Redis 为了对内存做极致的优化，不同长度的字符串使用不同的结构体来表示。embstr vs rawRedis 的字符串有两种存储方式，在长度特别短时，使用 emb 形式存储 (embeded)，当长度超过 44 时，使用 raw 形式存储。在字符串比较小时，SDS 对象头的大小是 capacity+3，至少是 3。意味着分配一个字符串的最小空间占用为 19 字节 (16+3)。RedisObject 占用 16 字节，SDS 占用 3 字节。 embstr 存储形式: 它将 RedisObject 对象头和 SDS 对象连续存在一起，使用 malloc 方法一次分配。 raw 存储形式: 它需要两次 malloc，两个对象头在内存地址上一般是不连续的。字符串是由多个字节组成，每个字节又是由 8 个 bit 组成，如此便可以将一个字符串看成很多 bit 的组合，这便是 bitmap「位图」数据结构。String 扩容当字符串长度小于 1M 时，扩容都是加倍现有的空间，也就是保留 100% 的冗余空间。如果超过 1M，扩容时一次只会多扩 1M 的空间。字符串最大长度为 512M。List 列表List 基础介绍Redis 的列表结构常用来做异步队列使用。比如秒杀场景将需要延后处理的任务结构体序列化成字符串塞进 Redis 的列表，另一个线程从这个列表中轮询数据进行处理。Redis 的列表相当于 Java 语言里面的 LinkedList，注意它是链表而不是数组。这意味着 list 的插入和删除操作非常快，时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为 O(n)，这点让人非常意外。List 常用命令# 对列 右进左出&amp;gt; rpush books python java golang(integer) 3&amp;gt; llen books(integer) 3&amp;gt; lpop books&quot;python&quot;...&amp;gt; lpop books(nil)# 栈 - 右进右出&amp;gt; rpush books python java golang(integer) 3&amp;gt; rpop books&quot;golang&quot;...&amp;gt; rpop books(nil)&amp;gt; lindex books 1 # O(n) 慎用&quot;java&quot;&amp;gt; lrange books 0 -1 # 获取所有元素，O(n) 慎用1) &quot;python&quot;2) &quot;java&quot;3) &quot;golang&quot;&amp;gt; ltrim books 1 -1 # O(n) 慎用OK&amp;gt; lrange books 0 -11) &quot;java&quot;2) &quot;golang&quot;&amp;gt; ltrim books 1 0 # 这其实是清空了整个列表，因为区间范围长度为负OK&amp;gt; llen books(integer) 0慢操作lindex 方法，它需要对链表进行遍历，性能随着参数 index 增大而变差。ltrim 和字面上的含义不太一样，个人觉得它叫 lretain(保留) 更合适一些，因为 ltrim 跟的两个参数 start_index 和 end_index 定义了一个区间，在这个区间内的值，ltrim 要保留，区间之外统统砍掉。我们可以通过 ltrim 来实现一个定长的链表，这一点非常有用。index 可以为负数，index=-1 表示倒数第一个元素，同样 index=-2 表示倒数第二个元素。list 底层结构Redis 底层存储的还不是一个简单的 linkedlist，而是称之为 快速链表 quicklist 的一个结构。首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是 ziplist，也就是压缩列表。它将所有的元素紧挨着一起存储，分配的是一块连续的内存。当数据量比较多的时候才会改成 quicklist。考虑到链表的附加空间相对太高，prev 和 next 指针就要占去 16 个字节 (64bit 系统的指针是 8 个字节)，另外每个节点的内存都是单独分配，会加剧内存的碎片化，影响内存管理效率。后续版本对列表数据结构进行了改造，使用 quicklist 代替了 ziplist 和 linkedlist。快速列表// 链表的节点struct listNode&amp;lt;T&amp;gt; { listNode* prev; listNode* next; T value;}// 链表struct list { listNode *head; listNode *tail; long length;}quicklist 是 ziplist 和 linkedlist 的混合体，它将 linkedlist 按段切分，每一段使用 ziplist 来紧凑存储，多个 ziplist 之间使用双向指针串接起来。压缩列表Redis 为了节约内存空间使用，zset 和 hash 容器对象在元素个数较少的时候，采用压缩列表 (ziplist) 进行存储。压缩列表是一块连续的内存空间，元素之间紧挨着存储，没有任何冗余空隙。struct ziplist&amp;lt;T&amp;gt; { int32 zlbytes; // 整个压缩列表占用字节数 int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点 int16 zllength; // 元素个数 T[] entries; // 元素内容列表，挨个挨个紧凑存储 int8 zlend; // 标志压缩列表的结束，值恒为 0xFF}struct entry { int&amp;lt;var&amp;gt; prevlen; // 前一个 entry 的字节长度 int&amp;lt;var&amp;gt; encoding; // 元素类型编码 optional byte[] content; // 元素内容}压缩列表为了支持双向遍历，所以才会有 ztail_offset 这个字段，用来快速定位到最后一个元素，然后倒着遍历。entry 的 prevlen 字段表示前一个 entry 的字节长度，当压缩列表倒着遍历时，需要通过这个字段来快速定位到下一个元素的位置。增加元素因为 ziplist 都是紧凑存储，没有冗余空间 (对比一下 Redis 的字符串结构)。意味着插入一个新的元素就需要调用 realloc 扩展内存。取决于内存分配器算法和当前的 ziplist 内存大小，realloc 可能会重新分配新的内存空间，并将之前的内容一次性拷贝到新的地址，也可能在原有的地址上进行扩展，这时就不需要进行旧内容的内存拷贝。如果 ziplist 占据内存太大，重新分配内存和拷贝内存就会有很大的消耗。所以 ziplist 不适合存储大型字符串，存储的元素也不宜过多。级联更新每个 entry 都会有一个 prevlen 字段存储前一个 entry 的长度。如果内容小于 254 字节，prevlen 用 1 字节存储，否则就是 5 字节。如果 ziplist 里面每个 entry 恰好都存储了 253 字节的内容，那么第一个 entry 内容的修改就会导致后续所有 entry 的级联更新，这就是一个比较耗费计算资源的操作。压缩深度quicklist 默认的压缩深度是 0，也就是不压缩。压缩的实际深度由配置参数 list-compress-depth 决定。为了支持快速的 push/pop 操作，quicklist 的首尾两个 ziplist 不压缩，此时深度就是 1。如果深度为 2，就表示 quicklist 的首尾第一个 ziplist 以及首尾第二个 ziplist 都不压缩。每个 ziplist 存多少元素？quicklist 内部默认单个 ziplist 长度为 8k 字节，超出了这个字节数，就会新起一个 ziplist。ziplist 的长度由配置参数 list-max-ziplist-size 决定。hash 字典hash 基础介绍hash 可以记录结构体信息，如帖子的标题、摘要、作者和封面信息、点赞数、评论数和点击数；缓存近期热帖内容Redis 的字典相当于 Java 语言里面的 HashMap，它是无序字典。内部实现结构是数组 + 链表二维结构。第一维 hash 的数组位置碰撞时，就会将碰撞的元素使用链表串接起来。Redis 为了高性能，不能堵塞服务，所以采用了渐进式 rehash 策略。过期策略 定时删除 redis 会将每个设置了过期时间的 key 放入到一个独立的字典中，以后会定时遍历这个字典来删除到期的 key。 惰性删除 惰性策略就是在客户端访问这个 key 的时候，redis 对 key 的过期时间进行检查，如果过期了就立即删除。 定时删除是集中处理，惰性删除是零散处理。 定期删除 Redis 默认会每 100ms 进行一次过期扫描，过期扫描不会遍历过期字典中所有的 key，而是采用了一种简单的贪心策略。 从过期字典中随机 20 个 key 删除这 20 个 key 中已经过期的 key 如果过期的 key 比率超过 1/4，那就重复步骤 1 同时，为了保证过期扫描不会出现循环过度，导致线程卡死现象，算法还增加了扫描时间的上限，默认不会超过 25ms。 对比 定时删除对内存友好，能够在 key 过期后立即从内存中删除，但是对 CPU 不友好，如果过期键较多会占用 CPU 对一些时间 惰性删除对 CPU 友好，只有在键用到的时候才会进行检查，对于很多用不到的 key 不用浪费时间进行检查，但是对内存不友好，过期 key 如果一直没用到就会一直在内存中，内存就得不到释放，从而造成内存泄漏。 定期删除可以通过限制操作时长和频率减少删除对 CPU 的影响，同时也能释放过期 key 占用的内存；但是频率和时长不太好控制，执行频繁了和定时一样占用 CPU，执行太少和惰性删除又一样对内存不好。 一般会使用组合策略 惰性删除 和 定期删除 组合使用。从库的过期策略从库不会进行过期扫描，从库对过期的处理是被动的。主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库，从库通过执行这条 del 指令来删除过期的 key。设想一个大型的 Redis 实例中所有的 key 在同一时间过期了，会出现怎样的结果？ 毫无疑问，Redis 会持续扫描过期字典 (循环多次)，直到过期字典中过期的 key 变得稀疏，才会停止 (循环次数明显下降)。这就会导致线上读写请求出现明显的卡顿现象。导致这种卡顿的另外一种原因是内存管理器需要频繁回收内存页，这也会产生一定的 CPU 消耗。当客户端请求到来时，服务器如果正好进入过期扫描状态，客户端的请求将会等待至少 25ms 后才会进行处理，如果客户端将超时时间设置的比较短，比如 10ms，那么就会出现大量的链接因为超时而关闭，业务端就会出现很多异常。而且这时你还无法从 Redis 的 slowlog 中看到慢查询记录，因为慢查询指的是逻辑处理过程慢，不包含等待时间。缓存雪崩造成缓存雪崩的关键在于在同一时间大规模的key失效。为什么会出现这个问题呢，第一种可能是Redis宕机，第二种可能是采用了相同的过期时间。解决办法： 所以业务开发人员一定要注意过期时间，如果有大批量的 key 过期，要给过期时间设置一个随机范围，而不宜全部在同一时间过期，分散过期处理的压力。避免缓存雪崩的发生。 双缓存。我们有两个缓存，缓存A和缓存B。缓存A的失效时间为20分钟，缓存B不设失效时间。自己做缓存预热操作。 设置热点数据永不过期。 提高数据库的容灾能力，可以使用分库分表，读写分离的策略 使用熔断机制。当流量到达一定的阈值时，就直接返回“系统拥挤”之类的提示，防止过多的请求打在数据库上。缓存穿透请求传进来的 key 是不存在 Redis 中的，那么就查不到缓存，查不到缓存就会去数据库查询。假如有大量这样的请求，这些请求像“穿透”了缓存一样直接打在数据库上，这种现象就叫做缓存穿透。这和缓存击穿有根本的区别，区别在于缓存穿透的情况是传进来的 key 在 Redis 中是不存在的。解决办法： 利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试 采用异步更新策略，无论key是否取到值，都直接返回。value 值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作。 判断请求是否有效的拦截机制，接口层做校验。比如，利用布隆过滤器，内部维护一系列合法有效的key。迅速判断出，请求所携带的Key是否合法有效。如果不合法，则直接返回，又如用户id基础校验，id&amp;lt;=0的直接过滤。缓存击穿缓存击穿是一个热点的 Key，有大并发集中对其进行访问，突然间这个 Key 失效了，导致大并发全部打在数据库上，导致数据库压力剧增。这种现象就叫做缓存击穿。解决办法： 如果业务允许的话，对于热点的key可以设置永不过期的key。 缓存预热，项目启动前，先加载缓存 使用互斥锁。如果缓存失效的情况，只有拿到锁才可以查询数据库，降低了在同一时刻打在数据库上的请求，防止数据库打死。当然这样会导致系统的性能变差。内存淘汰策略LRU：latest recent used.为了限制最大使用内存，Redis 提供了配置参数 maxmemory 来限制内存超出期望大小。Redis 提供了几种可选策略 (maxmemory-policy) 来让用户自己决定该如何腾出新的空间以继续提供读写服务 noeviction 不删除策略 不会继续服务写请求 (DEL 请求可以继续服务)，读请求可以继续进行。这样可以保证不会丢失数据，但是会让线上的业务不能持续进行。这是默认的淘汰策略。 volatile-lru 尝试淘汰设置了过期时间的 key 最少使用的 key 优先被淘汰。没有设置过期时间的 key 不会被淘汰，这样可以保证需要持久化的数据不会突然丢失。 volatile-ttl 淘汰设置了过期时间 key 中寿命小的key。而是 key 的剩余寿命 ttl 的值，ttl 越小越优先被淘汰。 volatile-random 淘汰的 key 是过期 key 集合中随机的 key。 allkeys-lru 区别于 volatile-lru，这个策略要淘汰的 key 对象是全体的 key 集合，而不只是过期的 key 集合。这意味着没有设置过期时间的 key 也会被淘汰。 allkeys-random 跟上面一样，不过淘汰的策略是随机的 key。 LRU 算法实现 LRU 算法除了需要 key/value 字典外，还需要附加一个链表，链表中的元素按照一定的顺序进行排列。当空间满的时候，会踢掉链表尾部的元素。当字典的某个元素被访问时，它在链表中的位置会被移动到表头。所以链表的元素排列顺序就是元素最近被访问的时间顺序。位于链表尾部的元素就是不被重用的元素，所以会被踢掉。位于表头的元素就是最近刚刚被人用过的元素，所以暂时不会被踢。近似 LRU 算法Redis 使用的是一种近似 LRU 算法，它跟 LRU 算法还不太一样。之所以不使用 LRU 算法，是因为需要消耗大量的额外的内存，需要对现有的数据结构进行较大的改造。近似 LRU 算法则很简单，在现有数据结构的基础上使用随机采样法来淘汰元素，能达到和 LRU 算法非常近似的效果。Redis 为实现近似 LRU 算法，它给每个 key 增加了一个额外的小字段，这个字段的长度是 24 个 bit，也就是最后一次被访问的时间戳。当 Redis 执行写操作时，发现内存超出 maxmemory，就会执行一次 LRU 淘汰算法。这个算法也很简单，就是随机采样出 5(可以配置) 个 key，然后淘汰掉最旧的 key，如果淘汰后内存还是超出 maxmemory，那就继续随机采样淘汰，直到内存低于 maxmemory 为止。采样按照 maxmemory-policy 的配置，如果是 allkeys 就是从所有的 key 字典中随机，如果是 volatile 就从带过期时间的 key 字典中随机。每次采样多少个 key 看的是 maxmemory_samples 的配置，默认为 5。LFURedis 4.0 里引入了一个新的淘汰策略 —— LFU 模式，全称是 Least Frequently Used，表示按最近的访问频率进行淘汰，它比 LRU 更加精准地表示了一个 key 被访问的热度。Redis 持久化Redis 的持久化机制有两种，第一种是快照，第二种是 AOF 日志。快照是一次全量备份，AOF 日志是连续的增量备份。快照是内存数据的二进制序列化形式，在存储上非常紧凑，而 AOF 日志记录 的是内存数据修改的指令记录文本。AOF 日志在长期的运行过程中会变的无比庞大，数据库重启时需要加载 AOF 日志进行指令重放，这个时间就会无比漫长。所以需要定期进行 AOF 重写，给 AOF 日志进行瘦身。RDB 快照原理Redis 使用操作系统的多进程 COW(Copy On Write) 机制来实现快照持久化。Redis 在持久化时会调用 glibc 的函数 fork 产生一个子进程，快照持久化完全交给子进程来处理，父进程继续处理客户端请求。子进程刚刚产生时，它和父进程共享内存里面的代码段和数据段。这是 Linux 操作系统的机制，为了节约内存资源，所以尽可能让它们共享起来。在进程分离的一瞬间，内存的增长几乎没有明显变化。子进程做数据持久化，它不会修改现有的内存数据结构，它只是对数据结构进行遍历读取，然后序列化写到磁盘中。但是父进程不一样，它必须持续服务客户端请求，然后对内存数据结构进行不间断的修改。随着父进程修改操作的持续进行，越来越多的共享页面被分离出来，内存就会持续增长。但是也不会超过原有数据内存的 2 倍大小。另外一个 Redis 实例里冷数据占的比例往往是比较高的，所以很少会出现所有的页面都会被分离，被分离的往往只有其中一部分页面。每个页面的大小只有 4K，一个 Redis 实例里面一般都会有成千上万的页面。。子进程因为数据没有变化，它能看到的内存里的数据在进程产生的一瞬间就凝固了，再也不会改变，这也是为什么 Redis 的持久化叫「快照」的原因。接下来子进程就可以非常安心的遍历数据了进行序列化写磁盘了。AOF 原理AOF 日志存储的是 Redis 服务器的顺序指令序列，AOF 日志只记录对内存进行修改的指令记录。假设 AOF 日志记录了自 Redis 实例创建以来所有的修改性指令序列，那么就可以通过对一个空的 Redis 实例顺序执行所有的指令，也就是「重放」，来恢复 Redis 当前实例的内存数据结构的状态。Redis 会在收到客户端修改指令后，进行参数校验进行逻辑处理后，如果没问题，就立即将该指令文本存储到 AOF 日志中，也就是先执行指令才将日志存盘。这点不同于 leveldb、hbase 等存储引擎，它们都是先存储日志再做逻辑处理。Redis 提供的 AOF 配置项 appendfsync 写回策略直接决定 AOF 持久化功能的效率和安全性。 always：同步写回，写指令执行完毕立马将aof_buf缓冲区中的内容刷写到 AOF 文件。 everysec：每秒写回，写指令执行完，日志只会写到 AOF 文件缓冲区，每隔一秒就把缓冲区内容同步到磁盘。 no：操作系统控制，写执行执行完毕，把日志写到 AOF 文件内存缓冲区，由操作系统决定何时刷写到磁盘。Redis 在长期运行的过程中，AOF 的日志会越变越长。如果实例宕机重启，重放整个 AOF 日志会非常耗时，导致长时间 Redis 无法对外提供服务。所以需要对 AOF 日志瘦身。AOF 重写Redis 提供了 bgrewriteaof 指令用于对 AOF 日志进行瘦身。其原理就是开辟一个子进程对内存进行遍历转换成一系列 Redis 的操作指令，序列化到一个新的 AOF 日志文件中。序列化完毕后再将操作期间发生的增量 AOF 日志追加到这个新的 AOF 日志文件中，追加完毕后就立即替代旧的 AOF 日志文件了，瘦身工作就完成了。 通常 Redis 的主节点是不会进行持久化操作，持久化操作主要在从节点进行。从节点是备份节点，没有来自客户端请求的压力，它的操作系统资源往往比较充沛。Redis 4.0 混合持久化重启 Redis 时，我们很少使用 rdb 来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 rdb 来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。将 rdb 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是自持久化开始到持久化结束的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小。于是在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。主从同步怎么实现的CAP 原理 C - Consistent ，一致性 A - Availability ，可用性 P - Partition tolerance ，分区容忍性分布式系统的节点往往都是分布在不同的机器上进行网络隔离开的，这意味着必然会有网络断开的风险，这个网络断开的场景的专业词汇叫着「网络分区」。网络分区发生时，一致性和可用性两难全。最终一致Redis 的主从数据是异步同步的，所以分布式的 Redis 系统并不满足「一致性」要求。当客户端在 Redis 的主节点修改了数据后，立即返回，即使在主从网络断开的情况下，主节点依旧可以正常对外提供修改服务，所以 Redis 满足「可用性」。Redis 保证「最终一致性」，从节点会努力追赶主节点，最终从节点的状态会和主节点的状态将保持一致。如果网络断开了，主从节点的数据将会出现大量不一致，一旦网络恢复，从节点会采用多种策略努力追赶上落后的数据，继续尽力保持和主节点一致。Redis 同步支持主从同步和从从同步，从从同步功能是 Redis 后续版本增加的功能，为了减轻主库的同步负担。增量同步Redis 同步的是指令流，主节点会将那些对自己的状态产生修改性影响的指令记录在本地的内存 buffer 中，然后异步将 buffer 中的指令同步到从节点，从节点一边执行同步的指令流来达到和主节点一样的状态，一边向主节点反馈自己同步到哪里了 (偏移量)。因为内存的 buffer 是有限的，所以 Redis 主库不能将所有的指令都记录在内存 buffer 中。Redis 的复制内存 buffer 是一个定长的环形数组，如果数组内容满了，就会从头开始覆盖前面的内容。如果因为网络状况不好，从节点在短时间内无法和主节点进行同步，那么当网络状况恢复时，Redis 的主节点中那些没有同步的指令在 buffer 中有可能已经被后续的指令覆盖掉了，从节点将无法直接通过指令流来进行同步，这个时候就需要用到更加复杂的同步机制 —— 快照同步。快照同步快照同步是一个非常耗费资源的操作，它首先需要在主库上进行一次 bgsave 将当前内存的数据全部快照到磁盘文件中，然后再将快照文件的内容全部传送到从节点。从节点将快照文件接受完毕后，立即执行一次全量加载，加载之前先要将当前内存的数据清空。加载完毕后通知主节点继续进行增量同步。在整个快照同步进行的过程中，主节点的复制 buffer 还在不停的往前移动，如果快照同步的时间过长或者复制 buffer 太小，都会导致同步期间的增量指令在复制 buffer 中被覆盖，这样就会导致快照同步完成后无法进行增量复制，然后会再次发起快照同步，如此极有可能会陷入快照同步的死循环。增加从节点当从节点刚刚加入到集群时，它必须先要进行一次快照同步，同步完成后再继续进行增量同步。无盘复制主节点在进行快照同步时，会进行很重的文件 IO 操作，特别是对于非 SSD 磁盘存储时，快照会对系统的负载产生较大影响。特别是当系统正在进行 AOF 的 fsync 操作时如果发生快照，fsync 将会被推迟执行，这就会严重影响主节点的服务效率。所谓无盘复制是指主服务器直接通过套接字将快照内容发送到从节点，生成快照是一个遍历的过程，主节点会一边遍历内存，一边将序列化的内容发送到从节点，从节点还是跟之前一样，先将接收到的内容存储到磁盘文件中，再进行一次性加载。Wait 指令Redis 的复制是异步进行的，wait 指令可以让异步复制变身同步复制，确保系统的强一致性 (不严格)。wait 指令是 Redis3.0 版本以后才出现的。&amp;gt; set key valueOK&amp;gt; wait 1 0(integer) 1wait 提供两个参数，第一个参数是从库的数量 N，第二个参数是时间 t，以毫秒为单位。它表示等待 wait 指令之前的所有写操作同步到 N 个从库 (也就是确保 N 个从库的同步没有滞后)，最多等待时间 t。如果时间 t=0，表示无限等待直到 N 个从库同步完成达成一致。假设此时出现了网络分区，wait 指令第二个参数时间 t=0，主从同步无法继续进行，wait 指令会永远阻塞，Redis 服务器将丧失可用性。" }, { "title": "MySQL - InnoDB 和 MyISAM 的区别", "url": "/posts/innodb-myisam/", "categories": "MySQL, InnoDB", "tags": "InnoDB, MyISAM", "date": "2022-01-19 20:30:00 +0800", "snippet": "InnoDB 和 MyISAM 的区别定义 InnoDB：MySQL 默认的存储引擎，是一个平衡了可靠性和高性能的通用存储引擎。从 MySQL-5.5 开始做为默认存储引擎。 MyISAM：在 MySQL-5.1 及之前的版本，MyISAM 是默认引擎。因为它不支持事务和行锁并且崩溃后无法恢复导致了它的没落，当然还是有很多优点的。区别事务InnoDB 支持事物，MyISAM 不支持索引InnoDB 使用 B+ 树聚簇索引，MyISAM 非聚簇索引全文索引InnoDB 5.6 以后开始支持全文索引，MyISAM 一直支持全文索引锁InnoDB 支持行锁、表锁，MyISAM 只支持表锁外键InnoDB 支持，MyISAM 不支持表行数InnoDB 没有保存，MyISAM 单独存储了，使用 count(*) 可以直接返回行数唯一主键InnoDB 必须要有唯一主键，MyISAM 可以没有 InnoDB 当没有主键时会选择唯一索引做为主键，再会自己使用隐藏列 row_id 做为主键文件存储InnoDB 数据和索引的文件存储在 *.ibd 的文件中，表结构是存在以 *.frm 为后缀的文件里，MyISAM 的索引和文件是分开的，*.MYD 存储表的数据、*.MYI 存储表索引，*.frm 是表结构文件总结 InnoDB 支持事务，外键，并发量大，适合大量的 update 操作 MyISAM 查询数据快，适合 select，不支持事务，并发量小，也没有 crash-safe" }, { "title": "MySQL 索引及常见面试题", "url": "/posts/mysql-index/", "categories": "MySQL, 索引", "tags": "index, 索引", "date": "2022-01-18 14:30:00 +0800", "snippet": "一、索引是什么？索引（Index）是帮助 MySQL 高效获取数据的数据结构，是对表中一列或多列值进行排序的结构。就比如索引是一本书的目录，可以通过目录快速查找自己想要查询的东西。二、索引为什么使用B+树？先看一下常见的索引存储结构 哈希表 是一种以键 - 值（key-value）存储数据的结构，我们只要输入待查找的值即 key，就可以找到其对应的值即 Value。哈希的思路很简单，把值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后 value 放在数组的这个位置。 哈希表这种结构适用于只有等值查询的场景 有序数组索引只适用于静态存储引擎，插入数据时必须得挪动后面的数据，成本太高. 二叉搜索树，每个节点的左儿子小于父节点，父节点又小于右儿子。二叉树做为索引就直接变成链表查找了。查找的时间复杂度是 O(log(N))。 任意节点左子树不为空,则左子树的值均小于根节点的值 任意节点右子树不为空,则右子树的值均大于于根节点的值 任意节点的左右子树也分别是二叉查找树 没有键值相等的节点 平衡二叉树 AVL 树是严格的平衡二叉树，所有节点的左右子树高度差不能超过1；AVL树查找、插入和删除在平均和最坏的情况下都是O(logn). 插入和删除可能破坏二叉树的平衡，此时需要通过一次或多次树旋转来重新平衡这棵树。当插入数据时，最多只需要1次旋转(单旋转或双旋转)；但是当删除数据时，会导致树失衡，AVL需要维护从被删除节点到根节点这条路径上所有节点的平衡，旋转的量级为O(lgn)。 但由于旋转的耗时，AVL树在删除数据时效率很低。 在删除操作较多时，维护平衡所需的代码可能高于其带来的好处，因此AVL实际应用并不广泛。 红黑树 红黑树相对于 AVL 树 只是确保从根到叶子的最长的可能路径不多于 最短的可能路径的两倍长 节点是红色或黑色 根节点是黑色 所有叶子是黑色的 每个红色节点必须有两个黑色的子节点(从每个叶子到根的所有路径上不能有两个连续的红色节点) 从任一节点到每个结点的所有简单路径都包含相同数目的黑色结点 对于数据在磁盘等辅助存储设备中的情况(如Mysql等数据库)，红黑树还是并不擅长，因为红黑树还是有点高。因为当数据在磁盘中，磁盘 IO 会成为最大的性能瓶颈，设计的目标应该是尽量减少IO次数；而树的高度越高，增删改查所需要的 IO 次数也越多，会严重影响性能。 “N 叉”树，N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。 以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。B- 树与 B+ 树的区别 B- 树B 树又称为 B- 树，是一种平衡多路查找树，描述B树，一般需要指定其阶数 M，阶数指的是一个节点包含的子节点最大数量。 每个节点最多有 M - 1 个关键字 除根节点外，其余的节点至少有 ceil（M/2）-1 个关键字（ceil为向上取整） 每个节点中的关键字都按照从小到大的顺序排列，每个关键字的左子树中的所有关键字都小于它，而右子树中的所有关键字都大于它 所有叶子节点都位于同一层，或者说根节点到每个叶子节点的长度都相同 B+ 树 B+ 树包含两种节点，一种是非叶子节点（还有一种叫法是内节点），一种是叶子节点 B+ 树与 B 树，最大的不同是 B+ 树的非叶子节点不保存数据，只用于索引，所有数据都保存在叶子节点 非叶子节点最多有 M - 1 个关键字，阶数 M 同时限制了叶子节点最多存储 M - 1 个记录 索引节点中的 key 都按照从小到大的顺序排列，对于内部节点中的一个 key，左子树中的所有 key 都小于它，右子树中的 key 都大于等于它。叶子节点中的记录也按照 key 的大小排列 每个叶子节点都存有相邻叶子节点的指针，叶子节点本身依关键字的大小从小到大顺序连接（范围查找特性） B树与 B+ 树的区别 B+ 树的层级更少：B+ 树非叶子节点上是不存储数据的，仅存储键值，叶子结点上存储数据，而 B 树节点中不仅存储键值，也会存储数据。所以一层中 B树可存储的数据就少；同时层级少了磁盘 IO 就少了查询的速度也就快了 B- 树查找到节点就可以返回数据，B+树如果是通过二级索引还需要回表查询（覆盖索引可以直接返回） B+树天然具备排序功能：B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时更方便，数据紧密型很高，缓存的命中率也会比B树高。 B+树全节点遍历更快：B+树遍历整棵树只需要遍历所有的叶子节点即可，而不需要像B树一样需要对每一层进行遍历 存储结构总结 二叉查找树(BST)：解决了排序的基本问题，但是由于无法保证平衡，可能退化为链表 平衡二叉树(AVL)：通过旋转解决了平衡的问题，但是旋转操作效率太低 红黑树：通过舍弃严格的平衡和引入红黑节点，解决了AVL旋转效率过低的问题，但是在磁盘等场景下，树仍然太高，IO次数太多 B树：通过将二叉树改为多路平衡查找树，解决了树过高的问题，但非叶子结点存储数据层级仍然不低 B+树： 在B树的基础上，将非叶节点改造为不存储数据的索引节点，进一步降低了树的高度 此外将叶节点使用指针连接成链表，范围查询更加高效 索引的文件存储 存储引擎为 MyISAM *.frm：与表相关的元数据信息都存放在 frm 文件，包括表结构的定义信息等 *.MYD：用于存储 MyISAM 表的数据 *.MYI：用于存储 MyISAM 表的索引相关信息 存储引擎为InnoDB*.frm：与表相关的元数据信息都存放在 frm 文件，包括表结构的定义信息等*.ibd：表数据和索引的文件。该表的索引(B+树)的每个非叶子节点存储索引，叶子节点存储索引和索引对应的数据三、索引的优缺点 优点 索引大大减小了服务器需要扫描的数据量，从而大大加快数据的检索速度 索引可以帮助服务器避免排序和临时表 索引可以将随机 IO 变成顺序 IO 索引对于 InnoDB（对索引支持行级锁）非常重要，因为它可以让查询锁更少的元组 关于InnoDB、索引和锁：InnoDB在二级索引上使用共享锁（读锁），但访问主键索引需要排他锁（写锁） 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性 可以加速表和表之间的连接 在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间 通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能 缺点 索引虽然提高了查询速度，但是随着数据的增加会增加维护和新建索引的耗时，如对表进行 INSERT、UPDATE 和 DELETE。因为更新表时，MySQL 不仅要保存数据，还要更新保存索引文件 建立索引会占用磁盘物理空间。一般情况这个问题不太严重，但如果你在一个大表上创建了多种组合索引，索引文件会变得非常大 如果某个数据列包含许多重复的内容，为它建立索引就没有太大的实际效果 对于非常小的表，大部分情况下简单的全表扫描更高效 四、索引的创建规则 应该创建索引的列 在经常需要查询的列上，可以加快搜索的速度 在主键的列上，强制该列的唯一性和组织表中数据的排列结构 在经常用在连接（JOIN）的列上，这些列主要是一外键，可以加快连接的速度 在经常需要根据范围（&amp;lt;，&amp;lt;=，=，&amp;gt;，&amp;gt;=，BETWEEN，IN）进行查询的列上创建索引，因为索引是有序的，其指定的范围是连续的 在经常需要排序（order by）的列上创建索引，因为索引是有序的，这样查询可以利用索引的有序性，不需要再进行排序直接可以返回 不应该创建索引的列 对于那些在查询中很少使用的列不应该创建索引 若列很少使用到，因此有索引或者无索引，并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。 对于那些只有很少数据值或者重复值多的列也不应该增加索引，也就是基数小的列不要建索引 这些列的取值很少，例如人事表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比例，即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度。 对于那些定义为 text, imag e和 bit 数据类型的列不应该增加索引 这些列的数据量要么相当大，要么取值很少，定义前缀索引区分度也不高 对修改频率高的列不要建索引，因为带来的查询效果已经远远低于频繁更新带来的维护索引的消耗 五、索引分类 从应用功能上分 主键索引 一张表只能有一个主键索引，不允许重复、不允许为 NULL ALTER TABLE TableName ADD PRIMARY KEY(column); 唯一索引 数据列不允许重复，允许为 NULL 值，一张表可有多个唯一索引，索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一 CREATE UNIQUE INDEX IndexName ON `TableName`(`column`(length)); ALTER TABLE TableName ADD UNIQUE (column); 二级索引（普通索引） 一张表可以创建多个普通索引，一个普通索引可以包含多个字段，允许数据重复，允许 NULL 值插入 CREATE INDEX IndexName ON `TableName`(`column`(length)); ALTER TABLE TableName ADD INDEX IndexName(`column`(length)); 联合索引 一个组合索引包含两个或两个以上的列。查询的时候遵循 mysql 组合索引的 “最左前缀”原则，即使用 where 时条件要按照建立索引的时候字段的排列方式放置索引才会生效。 CREATE INDEX IndexName ON `TableName`(`column`(length), `column`(length)); 全文索引 它查找的是文本中的关键词，主要用于全文检索 从数据结构上区分 聚簇索引 将数据存储与索引放到了一块，找到索引也就找到了数据。使用聚簇索引可以减少回表。 聚簇索引对于主键的排序查找和范围查找速度非常快 InnoDB 的聚簇索引： InnoDB 对主键建立聚簇索引。 如果你不指定主键，InnoDB 会用一个具有唯一且非空值的索引来代替。 如果不存在这样的索引，InnoDB 会定义一个隐藏的主键，然后对其建立聚簇索引。 由于聚簇索引是将数据跟索引结构放到一块，因此一个表仅有一个聚簇索引 非聚簇索引 将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行。 聚簇索引和非聚簇索引对比 聚簇索引优点 数据访问更快，因为聚簇索引将索引和数据保存在同一个B+树中，因此从聚簇索引中获取数据比非聚簇索引更快，一次将一页的数据和索引加载到内存，找到叶子结点就找到了数据，相对于普通索引减少了回表。 聚簇索引对于主键的排序查找和范围查找速度非常快，普通索引使用主键作为”指针”而不是使用地址值作为指针的好处是，减少了页分裂或页合并时对普通索引的维护，主键比指针占用更多的空间但是换来的是对索引的维护时间。 聚簇索引的缺点 插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，否则将会出现页分裂，严重影响性能。因此，对于InnoDB表，我们一般都会定义一个自增的ID列为主键，比如使用 uuid 时存储的数据稀疏，就出现使用聚簇索引可能比扫描全表还要慢。 更新主键的代价很高，因为将会导致被更新的行移动。 二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。 为什么建议使用自增 ID 做主键？ 减少页分裂：聚簇索引的数据的物理存放顺序与索引顺序是一致的，即：只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上的。如果主键不是自增 id，不断地调整数据的物理地址、分页，当然也有其他一些措施来减少这些操作，但却无法彻底避免。如果是自增的，那就简单了，它只需要一页一页地写，索引结构相对紧凑，磁盘碎片少，效率也高。 因为MyISAM的主索引并非聚簇索引，那么他的数据的物理地址必然是凌乱的，拿到这些物理地址，按照合适的算法进行I/O读取，于是开始不停的寻道不停的旋转。聚簇索引则只需一次I/O。（强烈的对比）不过，如果涉及到大数据量的排序、全表扫描、count之类的操作的话，还是MyISAM占优势些，因为索引所占空间小，这些操作是需要在内存中完成的。 六、索引查询InnoDB 的索引模型左侧为主键索引树，可以看到数据存在叶子结点上，右侧为普通索引树，叶子叶子结点存储的是主键值。主键越小，普通索引的叶子结点也就越小，普通索引占用的空间也就越小，根据普通索引查询时可以一次加载更多数据。根据主键和普通索引查询的过程 主键查询在索引树上查找，先是通过 B+ 树从树根开始，按层搜索到叶子节点，然后可以认为数据页内部通过二分法来定位记录，查询到叶子结点直接返回行数据，唯一索引与主键一样，查询到数据直接返回，如果使用的不是覆盖索引同样会多一步回表查询。 普通索引在普通索引树上查找，先是通过 B+ 树从树根开始，按层搜索到叶子节点，然后可以认为数据页内部通过二分法来定位记录，查询到叶子结点拿到主键值，再去主键树上进行查找返回对应的行记录。 全表扫描从根结点开始查找，加载到内存中，判断当前行数据是否目标值，是放到结果集中，继续下一行，知道扫描全表数据完成。通过索引树的扫描可以大大减少数据的检索量，同时因为维护索引树时数据是按照顺序维护的所以可以将一个查询的随机 IO 变成顺序 IO。查询时尽量使用主键索引，没有主键时就使用普通索引或者联合索引等，一定要避免全表扫描。索引的 join 连接查询select * from t1 straight_join t2 on (t1.a=t2.a);假设使用上面的语句进行查询， t2 的字段 a 上有索引。他的查询过程就是： 从表 t1 中读入一行数据 R；（此时对 t1 做的是全表扫描） 从数据行 R 中，取出 a 字段到表 t2 里去查找； 取出表 t2 中满足条件的行，跟 R 组成一行，作为结果集的一部分； 重复执行步骤 1 到 3，直到表 t1 的末尾循环结束。可以看到在查询 t2 时只需要根据索引树进行查询就可以了，不需要再进行全表扫描，这样减少了对 t2 的扫描。使用索引进行查询排序的过程select city, name, age from T where city = &#39;beijing&#39; order by name limit 1000; 假设 city, name 是一个联合索引 从索引 (city,name) 找到第一个满足 city=’beijing’条件的主键 id； 到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回； 从索引 (city,name) 取下一个记录主键 id； 重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city=’beijing’条件时循环结束。 假设 city, name, age 是一个联合索引，此时满足覆盖索引 从索引 (city,name,age) 找到第一个满足 city=’beijing’条件的记录，取出其中的 city、name 和 age 这三个字段的值，作为结果集的一部分直接返回； 从索引 (city,name,age) 取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回； 重复执行步骤 2，直到查到第 1000 条记录，或者是不满足 city=’beijing’条件时循环结束。 七、索引的实战最左前缀对于多列联合索引，索引的存储方式首先根据第一个列进行排序，第一个列相同的再根据第二个列进行排序插入，直到最后一个列，查询时首先根据第一个列进行匹配，如果直接根据第二个列进行匹配查询，他是无序的就用不上索引了，这就是最左前缀。当然一个有三个列的联合索引where条件进行三个等值查询可以不按照索引顺序进行查询，这个时候查询优化器会把三个列按照索引创建顺序进行调整。也就是覆盖索引查询时可以不按照索引列顺序进行 and 连接。覆盖索引select city, name, age from T where city = &#39;beijing&#39; and name = &quot;Jugg&quot; and age = 32;前面也提到了覆盖索引，还拿上面这个例子来说，city, name, age 三个列为联合索引，要查询的列全都在索引里面，这样就不需要回表进行查询，直接就返回数据了。覆盖索引的查询效率少了一次回表的过程，查询的效率会比普通索引查询的效率高。前缀索引有时候需要索引很长的字符列，这会让索引变得大且慢。通常可以以某列开始的部分字符作为索引，这样可以大大节约索引空间，从而提高索引效率。但这样也会降低索引的选择性。索引的选择性是指不重复的索引值和数据表的记录总数的比值，索引的选择性越高则查询效率越高。使用前缀索引时就没办法再使用覆盖索引了，因为前缀索引不知道当前字段是否完整，需要回表取整行数据进行判断。回表回到主键索引树搜索的过程，我们称为回表。普通索引存储的是索引键和主键值不能返回要筛选的全部字短，所以要回到主键树去查询整行数据进行返回。索引下推MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。索引失效情况 如果条件中有 or、is null、&amp;lt;&amp;gt; ，即使其中有条件带索引也不会使用，or 条件时主键可以使用索引 对于联合索引，不是使用的第一列也就是不使用最左前缀，则不会使用索引 like 查询是以通配符 % 开头，这样就会放弃索引走全表扫描，但是以 % 结尾没问题可以继续使用索引 如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引，如果列是数字类型条件中加引号同样可以走索引查询 如果mysql估计使用全表扫描要比使用索引快,则不使用索引 对索引列进行运算，比如函数计算就会索引失效普通索引和唯一索引的插入过程如果要在这张表中插入一个新记录 (4,400) 的话，InnoDB 的处理流程是怎样的? 第一种情况是，这个记录要更新的目标页在内存中。InnoDB 的处理流程如下： 对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束； 对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。 这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。 第二种情况是，这个记录要更新的目标页不在内存中。InnoDB 的处理流程如下： 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束； 对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。 索引的设计建议 索引字段尽量使用简单的数据类型，比如数字 因为在查询时对字符串的比较是逐个比较，耗费性能 数字比较小这样索引占用的空间会小 尽量不要让字段的默认值为 nullreference[MySQL索引总结] (https://zhuanlan.zhihu.com/p/29118331) [一文搞懂MySQL索引] (https://blog.csdn.net/wangfeijiu/article/details/113409719)" }, { "title": "Getting Started", "url": "/posts/new-first/", "categories": "Life, Tutorial", "tags": "notes", "date": "2022-01-15 15:00:00 +0800", "snippet": "started今天折腾了一下新域名 kekai.wang，不再维护自己的历史 demo 项目了（去年用 Gin 框架重构过一版），陆续 wangkekai.cn 和 wangkekai.com 也会迁移到这来～新站直接使用 github page 托管建站，主题选了好大一会，最后选择了 jekyll-theme-chirpy， 简洁、完善～process最近也是打算找工作，看了自己的笔记没多少可以直接复习的资料，有的也是零零散散的一些知识，所以打算做一个系列的面试资料，先写在前面看看能准备多少～ GoLang Redis MySQL 计算机网络 操作系统 分布式 高频算法题last年年都有 flag 却年年从未实现，希望今年可以完成 2021 年立下的一定要完成 2020 年说要做到的 2019 年曾经要完成的 2018 年的 flag！加油！！！" }, { "title": "Golang 开发规范 -- Go Code Review Comments", "url": "/posts/dev-standard/", "categories": "Go, comments", "tags": "develop, Go", "date": "2021-04-18 15:00:00 +0800", "snippet": "疫情期间入职新公司一个月了，部门每月会有知识分享，由大家轮流进行！ 我们的主力开发语言由 PHP 在逐步转向Go，参考 Go Code Review Comments 在上一次的部门分享我做的是 Go 语言的开发规范，在官方的基础上做了一个简单的分类，供大家参考共同学习。格式化gofmt通过gofmt自动格式化代码，以保证所有的go代码与官方推荐的格式保持一致。首字母大写和缩写当一个单词在代码中，可以是全小写的。也可以选择首字母大写，或者缩写。值得注意的是，一旦该单词选择了首字母大写或缩写的风格，就应当在整份代码中保持这种风格，不要首字母大写和缩写两种风格混用。以 URL 为例，如果选择了缩写 URL 这种风格，则应在整份代码中保持，以下命名都是不错的：URLPony，urlPony；切勿使用 UrlPony 这样的风格。代码行长度在 Golang 中，没有严格限制代码行长度，但我们应该尽量避免一行内写过长的代码，以及将长代码进行断行。每行不超过 80 个字符，依然是一个不错的建议。尽可能减少正常逻辑代码的缩进当函数调用返回错误时，我们需要判断错误是否为空，若不为空要进入错误处理的代码，结束后再进入正常逻辑代码。应当尽可能减少正常逻辑代码的缩进，这有利于提高代码的可读性，便于快速分辨出哪些还是正常逻辑代码。 段落引用尽早 return ：一有错误发生，马上返回。这是一个不好的代码风格，正常逻辑代码被缩进在else分支里面：if err != nil { //error handling} else { //normal code}这个是一个不错的代码风格，没有增加正常逻辑代码的缩进：if err != nil { // error handling return // or continue, etc.}// normal code另一种常见的情况，如果我们需要用函数的返回值来初始化某个变量，应该把这个函数调用单独写在一行，例如：x, err := f()if err != nil { // error handling return}// use x命名文件命名文件命名一律采用小写，不用驼峰，尽量见名思义，非测试文件禁止出现 *_test.go包命名包名应该是全小写单词，不要使用下划线；包名应该尽可能简短，长单词并不有助于可读性，尽量不要与标准库重名。变量命名一般采用驼峰，应该尽可能短，尤其是局部变量；对于特殊或全局变量可能需要对它有更多的描述建议使用长命名。函数与结构体命名必须为大小写驼峰模式，不要使用下划线，可以长，但是需要把函数功能描述清楚。例如：updateById，getUserInfo。函数名建议动词或者动宾结构单词，结构体建议名词或者动名词。单个变量、结构体的声明应该使用单行声明，两个或以上使用圆括号声明方式。枚举常量：使用类型前缀区分（理论上和文件名相同），采用驼峰。声明空数组切片这是一个推荐的做法：var t[]string这是不好的：golang t := []string{}原因是，前者能避免分配内存空间。有些时候，可能你从没向这个数组分片里面 append 元素。给函数返回值命名这是一个不好的代码风格，我们只知道函数返回的类型，但不知道每个返回值的名字：func (n *Node) Parent1 *Nodefunc (n *Node) parent2 (*Node, error)这是一个不错的代码风格，我们准确知道每个返回值的名字：func (n *Node) Parent1 (node *Node)func (n *Node) parent2 (node *Node, err error)这条建议几乎不需要过多的解释!尤其对于一种场景，当你需要在函数结束的 defer 中对返回值做一些事情，给返回值名字实在是太必要了。接受者命名结构体函数中，接受者的命名不应该采用 me，this，self 等通用的名字，而应该采用简短的（1或2个字符）并且能反映出结构体名的命名风格。例如，结构体名为 Client，接受者可以命名为 c 或者 cl。这样做的好处是，当生成了 godoc 后，过长或者过于具体的命名，会影响搜索体验。接受者类型编写结构体函数时，接受者的类型到底是选择值还是指针通常难以决定。 一条万能的建议：如果你不知道要使用哪种传递时，请选择指针传递吧！以下是一些不错的建议： 当接受者是 map, chan, func, 不要使用指针传递，因为它们本身就是引用类型。 当接受者是 slice，而函数内部不会对 slice 进行切片或者重新分配空间，不要使用指针传递。 当函数内部需要修改接受者，必须使用指针传递。 当接受者是一个结构体，并且包含了 sync.Mutex 或者类似的用于同步的成员。必须使用指针传递，避免成员拷贝。 当接受者类型是一个结构体并且很庞大，或者是一个大数组，建议使用指针传递来提高性能。 当接受者是结构体，数组或 slice，并且其中的元素是指针，并且函数内部可能修改这些元素，那么使用指针传递是个不错的选择，这能使得函数的语义更加明确。 当接受者是小型结构体，小数组，并且不需要修改里面的元素，里面的元素又是一些基础类型，使用值传递是个不错的选择。传递值而不是指针不要为了节省一点空间就传递指针而不是传递值。除非要传递的是一个庞大的结构体或者可预知在将来会变得非常庞大的结构体，指针是一个不错的选择。注释注释应当是一个完整的句子所有的注释都应该是一个完整的句子。句子应该以主语开头，句号结尾。这样做，能使注释在转化成 godoc 时有一个不错的格式。文档注释Go 提供两种注释风格，C 的块注释风格 /**/ ，C++ 的行注释风格 //每一个包都应该有包注释，位于文件的顶部，在包名出现之前。如果一个包有多个文件，包注释只需要出现在一个文件的顶部即可。包注释建议使用 C 注释风格，如果这个包特别简单，需要的注释很少，也可以选择使用 C++ 注释风格。每个 public 函数都应该有注释，注释句子应该以该函数名开头，如：// Encode writes the JSON encoding of req to w.func Encode(w io.Writer, req *Request) { ...error处理不要抛出 panic尽量不要使用 panic 处理错误。函数应该设计成多返回值，其中含括返回响应的 error 类型。error 提示错误提示不需要大写字母开头的单词，即使是句子的首字母也不需要。除非那是个专有名词或者缩写。同时，错误提示也不需要以句号结尾，因为通常在打印完错误提示后还需要跟随别的提示信息。处理错误不要将 error 赋值给匿名变量 _（因为你不可以使用匿名变量，当把 error 赋值给匿名变量后，相当于抛弃了这个 error）。如果一个函数返回 error，一定要检查它是否为空，判断函数调用是否成功。如果不为空，说明发生了错误，一定要处理它。imports当 import 多个包时，应该对包进行分组。同一组的包之间不需要有空行，不同组之间的包需要一个空行。标准库的包应该放在第一组。package mainimport ( &quot;fmt&quot; &quot;hash/adler32&quot; &quot;os&quot; &quot;appengine/foo&quot; &quot;appengine/user&quot; &quot;github.com/foo/bar&quot; &quot;rsc.io/goversion/version&quot;)流程控制ifIf 条件语句与PHP不同不需要圆括号，省略不必要的 else 语句。（左花括号必须与条件语句在同一行）// if接受初始化变量，约定如下方式建立局部变量if err := file.Chmod(666); err != nil { return err}for采用短声明建立局部变量，并且++或–是操作语句而非表达式for i := 0; i &amp;lt; 10; i++{}工程根目录规范${GOPATH}/src/${GIT_HOST}/{$GIT_USER}|${GIT_GROUP}/${PROJ_ROOT}GIT_HOST git 仓库 hostGIT_USER git 用户名称 同 GIT_GROUP 二选一GIT_GROUP git 工作组名称 GIT_USER 二选一PROJ_ROOT 项目根比如我的就在：github.com/wkk/goblog如有需要更正和不足之处请大家Email：wkekai@163.com 参考：Go Code Review Comments" } ]
